{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG Solution to the BiPedalWalker problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far we have seen the use of DQN and DDQN networks to solve RL problems. Such algorithms are limited in that they can only chose a single scalar action per timestep, i.e. a CHOICE of what action to take. Such problems are limited in reality as we often need to output a range of values for each action per timestep (i.e. a vector action). \n",
    "\n",
    "An example would be, in controlling a robot arm, we do not need a binary choice of which servo to *turn on* but a list of locations for each servo.\n",
    "\n",
    "Lets look at the actions spaces of two problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LunarLander-v2\n",
      "action space is shaped like  Discrete(4)\n",
      "state space size is (8,)\n",
      "\n",
      "BipedalWalker-v3\n",
      "action space is shaped like  Box(4,)\n",
      "state space size is (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdinneen/miniconda3/envs/aigym/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "envList=['LunarLander-v2', 'BipedalWalker-v3']\n",
    "for envName in envList:\n",
    "    env = gym.make(envName)\n",
    "    observation=env.reset()\n",
    "    print('\\n'+envName)\n",
    "    print('action space is shaped like ',env.action_space)\n",
    "    print('state space size is',env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with we are going to create two networks, an actor and a critic. The actor is going to determine the action values in the action vector and the critic is going to evaluate the value of these actions.\n",
    "\n",
    "(Note the code for this problem is heavily borrowed from  here: https://github.com/ghliu/pytorch-ddpg/blob/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0,
     1,
     4
    ]
   },
   "outputs": [],
   "source": [
    "class RandomProcess(object):\n",
    "    def reset_states(self):\n",
    "        pass\n",
    "\n",
    "class AnnealedGaussianProcess(RandomProcess):\n",
    "    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.n_steps = 0\n",
    "\n",
    "        if sigma_min is not None:\n",
    "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma_min\n",
    "        else:\n",
    "            self.m = 0.\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma\n",
    "\n",
    "    @property\n",
    "    def current_sigma(self):\n",
    "        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n",
    "        return sigma\n",
    "\n",
    "class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n",
    "    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
    "        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.size = size\n",
    "        self.reset_states()\n",
    "\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        self.state_dim = self.config.state_dim\n",
    "        self.action_dim = self.config.action_dim\n",
    "        self.batch_size = self.config.batch_size\n",
    "        self.gamma = self.config.gamma\n",
    "        self.epsilon = self.config.epsilon\n",
    "        self.is_training = True\n",
    "        self.randomer = OUNoise(self.action_dim)\n",
    "        self.buffer = ReplayBuffer(self.config.max_buff)\n",
    "\n",
    "        self.actor = Actor(self.state_dim, self.action_dim)\n",
    "        self.actor_target = Actor(self.state_dim, self.action_dim)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), self.config.learning_rate_actor)\n",
    "\n",
    "        self.critic = Critic(self.state_dim, self.action_dim)\n",
    "        self.critic_target = Critic(self.state_dim, self.action_dim)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), self.config.learning_rate)\n",
    "\n",
    "        hard_update(self.actor_target, self.actor)\n",
    "        hard_update(self.critic_target, self.critic)\n",
    "\n",
    "        if self.config.use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def learning(self):\n",
    "        s1, a1, r1, t1, s2 = self.buffer.sample_batch(self.batch_size)\n",
    "        # bool -> int\n",
    "        t1 = (t1 == False) * 1\n",
    "        s1 = torch.tensor(s1, dtype=torch.float)\n",
    "        a1 = torch.tensor(a1, dtype=torch.float)\n",
    "        r1 = torch.tensor(r1, dtype=torch.float)\n",
    "        t1 = torch.tensor(t1, dtype=torch.float)\n",
    "        s2 = torch.tensor(s2, dtype=torch.float)\n",
    "        if self.config.use_cuda:\n",
    "            s1 = s1.cuda()\n",
    "            a1 = a1.cuda()\n",
    "            r1 = r1.cuda()\n",
    "            t1 = t1.cuda()\n",
    "            s2 = s2.cuda()\n",
    "\n",
    "        a2 = self.actor_target(s2).detach()\n",
    "        target_q = self.critic_target(s2, a2).detach()\n",
    "        y_expected = r1[:, None] + t1[:, None] * self.config.gamma * target_q\n",
    "        y_predicted = self.critic.forward(s1, a1)\n",
    "\n",
    "        # critic gradient\n",
    "        critic_loss = nn.MSELoss()\n",
    "        loss_critic = critic_loss(y_predicted, y_expected)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        loss_critic.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # actor gradient\n",
    "        pred_a = self.actor.forward(s1)\n",
    "        loss_actor = (-self.critic.forward(s1, pred_a)).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        loss_actor.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # Notice that we only have gradient updates for actor and critic, not target\n",
    "        # actor_optimizer.step() and critic_optimizer.step()\n",
    "\n",
    "        soft_update(self.actor_target, self.actor, self.config.tau)\n",
    "        soft_update(self.critic_target, self.critic, self.config.tau)\n",
    "\n",
    "        return loss_actor.item(), loss_critic.item()\n",
    "\n",
    "\n",
    "    def cuda(self):\n",
    "        self.actor.cuda()\n",
    "        self.actor_target.cuda()\n",
    "        self.critic.cuda()\n",
    "        self.critic_target.cuda()\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon -= self.config.eps_decay\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "        if self.config.use_cuda:\n",
    "            state = state.cuda()\n",
    "\n",
    "        action = self.actor(state).detach()\n",
    "        action = action.squeeze(0).cpu().numpy()\n",
    "        action += self.is_training * max(self.epsilon, self.config.epsilon_min) * self.randomer.noise()\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "\n",
    "        self.action = action\n",
    "        return action\n",
    "\n",
    "    def reset(self):\n",
    "        self.randomer.reset()\n",
    "\n",
    "    def load_weights(self, output):\n",
    "        if output is None: return\n",
    "        self.actor.load_state_dict(torch.load('{}/actor.pkl'.format(output)))\n",
    "        self.critic.load_state_dict(torch.load('{}/critic.pkl'.format(output)))\n",
    "\n",
    "    def save_model(self, output):\n",
    "        torch.save(self.actor.state_dict(), '{}/actor.pkl'.format(output))\n",
    "        torch.save(self.critic.state_dict(), '{}/critic.pkl'.format(output))\n",
    "\n",
    "    def save_config(self, output, save_obj=False):\n",
    "\n",
    "        with open(output + '/config.txt', 'w') as f:\n",
    "            attr_val = get_class_attr_val(self.config)\n",
    "            for k, v in attr_val.items():\n",
    "                f.write(str(k) + \" = \" + str(v) + \"\\n\")\n",
    "\n",
    "        if save_obj:\n",
    "            file = open(output + '/config.obj', 'wb')\n",
    "            pickle.dump(self.config, file)\n",
    "            file.close()\n",
    "\n",
    "    def save_checkpoint(self, ep, total_step, output):\n",
    "\n",
    "        checkpath = output + '/checkpoint_model'\n",
    "        os.makedirs(checkpath, exist_ok=True)\n",
    "\n",
    "        torch.save({\n",
    "            'episodes': ep,\n",
    "            'total_step': total_step,\n",
    "            'actor': self.actor.state_dict(),\n",
    "            'critic': self.critic.state_dict()\n",
    "        }, '%s/checkpoint_ep_%d.tar'% (checkpath, ep))\n",
    "\n",
    "\n",
    "    def load_checkpoint(self, model_path):\n",
    "        checkpoint = torch.load(model_path)\n",
    "        episode = checkpoint['episodes']\n",
    "        total_step = checkpoint['total_step']\n",
    "        self.actor.load_state_dict(checkpoint['actor'])\n",
    "        self.critic.load_state_dict(checkpoint['critic'])\n",
    "\n",
    "        return episode, total_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     45,
     50,
     51
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, buffer_size, random_seed=123):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.count = 0\n",
    "        self.buffer = []\n",
    "        random.seed(random_seed)\n",
    "\n",
    "    def add(self, s, a, r, t, s2):\n",
    "        # add an experience to the buffer.\n",
    "        # Note t is a bool for terminal state.\n",
    "        experience = (s, a, r, t, s2)\n",
    "        # IF we are at less than capacity Add to buffer.\n",
    "        if self.count < self.buffer_size:\n",
    "            self.buffer.append(experience)\n",
    "            self.count += 1\n",
    "        else:\n",
    "        # Otherwise do a LIFO style rotation.\n",
    "            self.buffer.pop(0)\n",
    "            self.buffer.append(experience)\n",
    "\n",
    "    def size(self):\n",
    "        return self.count\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        if self.count < batch_size:\n",
    "            batch = random.sample(self.buffer, self.count)\n",
    "        else:\n",
    "            batch = random.sample(self.buffer, batch_size)\n",
    "\n",
    "        s_batch = np.array([_[0] for _ in batch])\n",
    "        a_batch = np.array([_[1] for _ in batch])\n",
    "        r_batch = np.array([_[2] for _ in batch])\n",
    "        t_batch = np.array([_[3] for _ in batch])\n",
    "        s2_batch = np.array([_[4] for _ in batch])\n",
    "\n",
    "        return s_batch, a_batch, r_batch, t_batch, s2_batch\n",
    "\n",
    "    def clear(self):\n",
    "        self.buffer = []\n",
    "        self.count = 0\n",
    "\n",
    "    def save(self):\n",
    "        file = open('replay_buffer.obj', 'wb')\n",
    "        pickle.dump(self.buffer, file)\n",
    "        file.close()\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            filehandler = open('replay_buffer.obj', 'rb')\n",
    "            self.buffer = pickle.load(filehandler)\n",
    "            self.count = len(self.buffer)\n",
    "        except:\n",
    "            print('there was no file to load')\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episodes=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-732b54c9af91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reset'"
     ]
    }
   ],
   "source": [
    "agent=Actor(),Critic\n",
    "all_rewards = []\n",
    "for ep in range(max_episodes):\n",
    "    s0 = env.reset()\n",
    "    agent.reset()\n",
    "\n",
    "    done = False\n",
    "    step = 0\n",
    "    actor_loss, critics_loss, reward = 0, 0, 0\n",
    "\n",
    "    # decay noise\n",
    "    agent.decay_epsilon()\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(s0)\n",
    "\n",
    "        s1, r1, done, info = env.step(action)\n",
    "        agent.buffer.add(s0, action, r1, done, s1)\n",
    "        s0 = s1\n",
    "\n",
    "        if agent.buffer.size() > config.batch_size:\n",
    "            loss_a, loss_c = agent.learning()\n",
    "            actor_loss += loss_a\n",
    "            critics_loss += loss_c\n",
    "\n",
    "        reward += r1\n",
    "        step += 1\n",
    "        total_step += 1\n",
    "\n",
    "        if step + 1 > config.max_steps:\n",
    "            break\n",
    "\n",
    "    all_rewards.append(reward)\n",
    "    avg_reward = float(np.mean(all_rewards[-100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from gym import wrappers, envs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for simulation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdinneen/miniconda3/envs/aigym/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from misc import epsilon_threshold, plot_eps\n",
    "\n",
    "\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "# Turn interactive mode on.\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using', device, 'for simulation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor_Network(nn.Module):\n",
    "    '''Actor network\n",
    "    Inputs are ints of size'''\n",
    "    def __init__(self, state, action,hidden1=150, hidden2=120):\n",
    "        super(Actor_Network, self).__init__()\n",
    "        self.FCL1 = nn.Linear(state,hidden1)\n",
    "        self.FCL2 = nn.Linear(hidden1,hidden2)\n",
    "        self.FCL3 = nn.Linear(hidden2,action)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''input states, return action'''\n",
    "        x = F.relu(self.FCL1(x))\n",
    "        x = F.relu(self.FCL2(x))\n",
    "        x = torch.tanh(self.FCL3(x))\n",
    "        return x\n",
    "    \n",
    "class Critic_Network(nn.Module):\n",
    "    '''A Deep Q network for predicting actions given states'''\n",
    "    def __init__(self, state, action, hidden1=150, hidden2=120):\n",
    "        super(Critic_Network, self).__init__()\n",
    "        self.FCL1 = nn.Linear(state,hidden1)\n",
    "        self.FCL2 = nn.Linear(hidden1+action, hidden2)\n",
    "        self.FCL3 = nn.Linear(hidden2,1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        '''input stateaction, output value'''\n",
    "        x = F.relu(self.FCL1(state))\n",
    "        x = self.FCL2(torch.cat([x,action],dim=1))\n",
    "        x = F.relu(x)\n",
    "        x = self.FCL3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A mapping of state-action pairs to next-state reward results'''\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    '''a cyclic buffer of bounded size that holds recently observed transitions.'''\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            # if we are at less than capacity, allocate fresh space for the transition\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        '''Randomly return a batch of batch_size from the memory'''\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, training=True):\n",
    "    '''torch.tensor -> torch.tensor\n",
    "    \n",
    "    Chooses an epsilon-greedy action given an input state.'''\n",
    "    action = policy_actor_net(state).detach()\n",
    "    action = action.squeeze(0).cpu().numpy()\n",
    "    action += training * max(epsilon, epsilon_min) #* noise()\n",
    "    action = np.clip(action, -1.0, 1.0)\n",
    "    return action\n",
    "\n",
    "def soft_update(target, source, tau=0.001):\n",
    "    \"\"\"\n",
    "    update target by target = tau * source + (1 - tau) * target\n",
    "    :param target: Target network\n",
    "    :param source: source network\n",
    "    :param tau: 0 < tau << 1\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - tau) + param.data * tau\n",
    "        )    \n",
    "    \n",
    "def optimize_model():\n",
    "    '''\n",
    "    None -> float,float\n",
    "    \n",
    "    Update the actor and critic networks via SGD.\n",
    "    returns actor loss and critic loss.\n",
    "    '''\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        #print(\"Warning: We do not have enough history in memory to optimize our network\")\n",
    "        return\n",
    "    \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch \n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    next_state_batch = torch.cat(batch.next_state)\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    \n",
    "    # Compute A(s_{t+1}) for all next states.\n",
    "    next_action_batch = torch.zeros((BATCH_SIZE,n_actions), device=device)\n",
    "    next_action_batch[non_final_mask] = target_actor_net(non_final_next_states).detach()\n",
    "\n",
    "    target_q = target_critic_net(next_state_batch, next_action_batch).detach()\n",
    "    \n",
    "    y_expected = reward_batch + gamma * target_q\n",
    "    y_predicted = policy_critic_net.forward(state_batch, action_batch)\n",
    "\n",
    "    # critic gradient\n",
    "    critic_loss = nn.MSELoss()\n",
    "    loss_critic = critic_loss(y_predicted, y_expected)\n",
    "    critic_optimizer.zero_grad()\n",
    "    loss_critic.backward()\n",
    "    critic_optimizer.step()\n",
    "\n",
    "    # actor gradient\n",
    "    pred_a = policy_actor_net.forward(state_batch)\n",
    "    loss_actor = (-policy_critic_net.forward(state_batch, pred_a)).mean()\n",
    "    actor_optimizer.zero_grad()\n",
    "    loss_actor.backward()\n",
    "    actor_optimizer.step()\n",
    "    \n",
    "    soft_update(target_actor_net, policy_actor_net, tau=0.001)\n",
    "    soft_update(target_critic_net, policy_critic_net, tau=0.001)\n",
    "    #target_actor_net.parameters().data.copy_(target_actor_net.parameters().data*(1.0 -tau) + tau*policy_actor_net.parameters())\n",
    "    #target_critic_net.parameters().data.copy_(target_critic_net.parameters().data*(1.0 -tau) + tau*policy_critic_net.parameters())\n",
    "    \n",
    "    return loss_actor.item(), loss_critic.item()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ToDo:\n",
    "\n",
    "implement noise.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 4\n",
    "# Get length of state space from gym observation space\n",
    "n_states = 24\n",
    "\n",
    "# Create two actor networks\n",
    "policy_actor_net = Actor_Network(n_states, n_actions).to(device)\n",
    "target_actor_net = Actor_Network(n_states, n_actions).to(device)\n",
    "# Duplicate the weights and biases of the policy net into the target net.\n",
    "target_actor_net.load_state_dict(policy_actor_net.state_dict())\n",
    "\n",
    "# Create two critic networks\n",
    "policy_critic_net = Critic_Network(n_states, n_actions).to(device)\n",
    "target_critic_net = Critic_Network(n_states, n_actions).to(device)\n",
    "# Duplicate the weights and biases of the policy net into the target net.\n",
    "target_critic_net.load_state_dict(policy_critic_net.state_dict())\n",
    "\n",
    "target_actor_net.eval()\n",
    "target_critic_net.eval()\n",
    "\n",
    "actor_optimizer = optim.Adam(policy_actor_net.parameters(),lr=0.001)\n",
    "critic_optimizer = optim.Adam(policy_critic_net.parameters(),lr=0.001)\n",
    "# Initialise the memory object.\n",
    "memory = ReplayMemory(200000)\n",
    "memory.clear()\n",
    "\n",
    "steps_done = 0\n",
    "episode_durations = []\n",
    "reward_values = []\n",
    "action_values=[]\n",
    "frame_values=[]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "# Discount Factor\n",
    "GAMMA = 0.99\n",
    "epsilon=0.2\n",
    "epsilon_min=0.05\n",
    "\n",
    "gamma=0.99\n",
    "\n",
    "\n",
    "# How often do we update our policy network parameters (in steps)\n",
    "TARGET_UPDATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n",
      "Warning: We do not have enough history in memory to optimize our network\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 20 in argument 0, but got NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-23d0d806829d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-235-e29428eb4cbf>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0maction_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mreward_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mnext_state_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Compute a mask of non-final states and concatenate the batch elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 20 in argument 0, but got NoneType"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "for i_episode in range(num_episodes):\n",
    "    state = torch.from_numpy(np.cast['float32'](env.reset())).unsqueeze(0).to(device)\n",
    "    TotalReward=0\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        env.render()\n",
    "        TotalReward+= reward\n",
    "        action = torch.from_numpy(np.cast['float32'](action)).unsqueeze(0).to(device)\n",
    "        next_state = torch.from_numpy(np.cast['float32'](next_state)).unsqueeze(0).to(device)\n",
    "        reward = torch.tensor([reward], device=device,dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        if not done:\n",
    "            next_state = next_state\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            reward_values.append(TotalReward)\n",
    "            break\n",
    "        \n",
    "   # if i_episode % TARGET_UPDATE == 0:\n",
    "        # Update the target network, copying all weights and biases in DQN\n",
    "        #target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "#env.render()\n",
    "env.close()\n",
    "#plt.ioff()\n",
    "#plt.show()\n",
    "#plot_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((24,4), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
