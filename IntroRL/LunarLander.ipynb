{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LunarLander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LunarLander-v2\n",
    "\n",
    "__Description__\n",
    "\n",
    "+ Landing pad is always at coordinates (0,0). \n",
    "\n",
    "+ Coordinates are the first two numbers in state vector. \n",
    "\n",
    "+ Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points. \n",
    "+ If lander moves away from landing pad it loses reward back. \n",
    "+ Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. \n",
    "+ Each leg ground contact is +10. \n",
    "+ Firing main engine is -0.3 points each frame. \n",
    "+ Solved is 200 points. \n",
    "+ Landing outside landing pad is possible. \n",
    "+ Fuel is infinite, so an agent can learn to fly and then land on its first attempt. \n",
    "+ Four discrete actions available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from gym import wrappers, envs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the various spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space size is Discrete(4)\n",
      "state space size is (8,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "observation=env.reset()\n",
    "print('action space size is',env.action_space)\n",
    "print('state space size is',env.observation_space.shape)#env.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo (render=False):\n",
    "    '''\n",
    "    boolean - > float.\n",
    "    \n",
    "    Run the lunar lander game using completly random inputs and optionally show the movie.\n",
    "    Returns the reward of the demo.'''\n",
    "    env = gym.make('LunarLander-v2')\n",
    "    TotalReward=0\n",
    "    done=False\n",
    "    observation=env.reset()\n",
    "    while not done:\n",
    "        # Render the environment to screen.\n",
    "        if render:\n",
    "            env.render()\n",
    "        # Pause such that this loop creates a 10Hz movie of the system.\n",
    "        time.sleep(0.02)\n",
    "        # Choose a random action\n",
    "        action=env.action_space.sample()\n",
    "        # Enact the chosen action and recieve a reward.\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        TotalReward+=reward\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return TotalReward\n",
    "\n",
    "#demo(render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(num_demos=1):\n",
    "    '''\n",
    "    int -> list\n",
    "    \n",
    "    run the demo program n times\n",
    "    Return a list of scores.\n",
    "    \n",
    "    '''\n",
    "    AllRewards=[]\n",
    "\n",
    "    for i in range(num_demos):\n",
    "        AllRewards.append(demo())\n",
    "    return AllRewards\n",
    "\n",
    "#i=20\n",
    "#Runs=benchmark(i)\n",
    "#print('Average reward of',i,'random runs:', sum(Runs)/len(Runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for simulation.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "# Turn interactive mode on.\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using', device, 'for simulation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_threshold (steps, EPS_START = 0.9, EPS_END = 0.05, EPS_DECAY = 200):\n",
    "    '''float -> float\n",
    "    \n",
    "    Return the probabilty of selecting exploration in a RL step.\n",
    "    '''\n",
    "\n",
    "    return min(EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps / EPS_DECAY),1.0)\n",
    "\n",
    "def plot_eps (max_steps=1000,EPS_START = 0.9, EPS_END = 0.05, EPS_DECAY = 200):\n",
    "    '''int,float,float,int -> None\n",
    "    \n",
    "    Plot the probability of an exploration step vs number of steps.\n",
    "    \n",
    "    max_steps:    Maximum number of steps to plot\n",
    "    EPS_START:    Initial Probabilty at step=0\n",
    "    EPS_END:      Final probability at step=infinity\n",
    "    EPS_DECAY:    Sort of like a Half-life of decay in steps'''\n",
    "    \n",
    "    epsilon=[]\n",
    "    steps=[]\n",
    "    for step in range(max_steps):\n",
    "        steps.append(step)\n",
    "        epsilon.append(epsilon_threshold(step,EPS_START=EPS_START, EPS_END=EPS_END,EPS_DECAY=EPS_DECAY))\n",
    "\n",
    "\n",
    "    fig=plt.figure()\n",
    "    plt.ylim((0,1.05))\n",
    "    plt.xlim((0,max_steps))\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Probability of exploration\")\n",
    "    plt.plot(steps,epsilon)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "'''A mapping of state-action pairs to next-state reward results'''\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    '''a cyclic buffer of bounded size that holds recently observed transitions.'''\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            # if we are at less than capacity, allocate fresh space for the transition\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        '''Randomly return a batch of batch_size from the memory'''\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    '''A Deep Q network for predicting actions given states'''\n",
    "    def __init__(self, inputs, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        # inputs are the 4 vector state space\n",
    "        self.FCL1 = nn.Linear(8,150)\n",
    "        self.FCL2 = nn.Linear(150,120)\n",
    "        self.FCL3 = nn.Linear(120,4)\n",
    "        # Output is a Q value allocated to each action.\n",
    "        #\n",
    "        #       input    hidden   hidden  hidden  output\n",
    "        #       layer    layer1   layer2  layer3  layer\n",
    "        #size    8         16       64      16      4\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.FCL1(x))\n",
    "        x = F.relu(self.FCL2(x))\n",
    "        x = self.FCL3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    '''??? -> torch\n",
    "    \n",
    "    Chooses an epsilon-greedy action given an input state.'''\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = min(EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY),1.0)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            action=policy_net(state).max(1)[1].view(1, 1)\n",
    "            return action\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "def plot_durations():\n",
    "    '''Show the numder of durations per episode on the yaxis.\n",
    "    After 100 episodes also plot a moving average.\n",
    "    '''\n",
    "    plt.figure(2,figsize=(20,10)) \n",
    "    #plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        #display.display(plt.gcf())\n",
    "        \n",
    "def plot_reward(meanscale=10):\n",
    "    '''Show the reward per episode on the yaxis.\n",
    "    After 100 episodes also plot a moving average.\n",
    "    '''\n",
    "    plt.figure(2,figsize=(20,10)) \n",
    "    #plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(reward_values)\n",
    "    # Take 100 episode averages and plot them too\n",
    "    #if len(durations_t) >= meanscale:\n",
    "     #   means = sum(total_reward[-meanscale:])/len(meanscale)\n",
    "     #   means = torch.cat((torch.zeros(99), means))\n",
    "     #   plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        #display.display(plt.gcf())\n",
    "\n",
    "def optimize_model():\n",
    "    '''\n",
    "    None -> None\n",
    "    \n",
    "    Update the DQN policy network via SGD.\n",
    "    '''\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        print(\"Warning: We do not have enough history in memory to optimize our network\")\n",
    "        return\n",
    "    \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch \n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    \n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    # Compute Huber loss\n",
    "    loss = F.mse_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    loss_values.append(loss)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get length of state space from gym observation space\n",
    "n_states = env.observation_space.shape[0]\n",
    "\n",
    "# Create two networks\n",
    "policy_net = DQN(n_states, n_actions).to(device)\n",
    "target_net = DQN(n_states, n_actions).to(device)\n",
    "# Duplicate the weights and biases of the policy net into the target net.\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(),lr=0.001)\n",
    "# Initialise the memory object.\n",
    "memory = ReplayMemory(200000)\n",
    "\n",
    "steps_done = 0\n",
    "episode_durations = []\n",
    "reward_values = []\n",
    "loss_values =[]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Learning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gU57n+8e8jCQSiSIBElxC9d9EJhjj2ARsbd4MbrrjEjhPnXMfx75zE6dVx4hbbuLfYiVvce8M2HUyvoosmCRBFFFGe3x+7BEUW2kXS7qrcn+vaS5rZ2Zlnx7ZuzzvvvK+5OyIiImWJi3UBIiJS9SksREQkJIWFiIiEpLAQEZGQFBYiIhJSQqwLOFWpqamemZkZ6zJERKqVefPm5bt7Wnk/X+3CIjMzk7lz58a6DBGRasXMNlTk82qGEhGRkBQWIiISksJCRERCUliIiEhICgsREQlJYSEiIiFFLCzM7EkzyzWzJSd538zsfjPLNrNFZjYgUrWIiEjFRPI5i6eBB4FnT/L+OKBz8DUEeDj4s0zucPDw0UoqMXwJcUZCvC7ERKR2ilhYuPs0M8ssY5MJwLMemFBjppmlmFkrd99a1n6XbNlNt5++X4mVhiepbjxXD8/kxlEdSU6qE/Xji4jEUiyf4G4DbCq2nBNc962wMLMpwBSAZm3ac+fYblEpsLilW3bzt8/X8PzMDdx4WkeuG9meenXio16HiEgsxDIsrJR1pU7b5+5TgakAWVlZfvPojpGs66RuGb2Hez9ayZ8+WMk3Gwt49MqBxMeV9jVERGqWWDbC5wDpxZbbAltiVEtYerRuzOOTB/GLc3vy8fLt/OrtZbEuSUQkKmIZFm8CVwV7RQ0Fdoe6X1FVTB6eyfUj2/P09PU88dW6WJcjIhJxEWuGMrMXgdFAqpnlAHcDdQDc/RHgXeAsIBvYD1wTqVoi4f+d1Z2cXQf49TvLaJNSn7G9Wsa6JBGRiLFAZ6TqIysry6vKEOUHio4y6bGZLN+6h7/fMJSB7ZrEuiQRkVKZ2Tx3zyrv5/XgQAXUrxvPE5OzaJVcj+ufmcPavH2xLklEJCIUFhXUrGEiz1w7mDgzJj81m7y9h2JdkohIpVNYVIJ2zRrwxNWDyN9bxHXPzKHw0JFYlyQiUqkUFpWkX3oKD17Wn6Vb9nDzC/M5fPRYrEsSEak0CotKdHr3Fvz2/F5MW5XHna8s4tix6tV5QETkZGL5BHeNdOmgDPL2HuKeD1eR1iiRu87qHuuSREQqTGERAd8f04ncvYd4dNpaUhsmcsOoDrEuSUSkQhQWEWBm3H1OT3bsK+I37y4nJakOF2elh/6giEgVpbCIkPg4495L+7L7wGF+8tpikuvX4cyeespbRKon3eCOoMSEeB69ciC92iRz64vfMHPtjliXJCJSLgqLCGuQmMDTVw8io2kS1z8zl8U5u2NdkojIKVNYREGTBnV57rrBJNevw1VPzmL19r2xLklE5JQoLKKkVXJ9Xrh+CAnxcVzxxCw27dwf65JERMKmsIiizNQGPHfdYA4ePsblj89i+56DsS5JRCQsCoso69ayMU9fM4gd+w5x2WMzyd+ngQdFpOpTWMRA/4wmPHH1IDYXHODKJ2ZTsL8o1iWJiJRJYREjQzs049Ers1iTu4/JT81h78HDsS5JROSkFBYxdFqXNB66fABLN+/m2qc1tLmIVF0Kixg7o0cL7pvYn3kbdnHdM3M4UHQ01iWJiHyLwqIKOLtPK/5yaT9mrdvJDc/O5eBhBYaIVC0KiypiQr82/Omivny9Jp8bn5unwBCRKkVhUYVcNLAtvzu/N1+syuPm5xUYIlJ1KCyqmImDM/jdBb35bGUgMA4dUWCISOwpLKqgScUC4yY1SYlIFaCwqKImDc7gt+cHAkP3MEQk1hQWVdhlQzL4/QW9mbY6jxuenatutSISMwqLKm7i4Az+eGEfvsrO57pn5rC/SA/uiUj0KSyqgYuz0rn3kr7MXLuDq5/U0CAiEn0Ki2ri/P5tA096b9zFlU/MZvcBBYaIRI/Coho5p29rHr58AMu27OGyx2ays1Cj1YpIdCgsqpkze7Zk6lUDyc7dx8SpM8jVBEoiEgVhhYWZxZtZazPLOP6KdGFycqO7NuepawaRs+sAFz86Q1O0ikjEhQwLM7sN2A58BLwTfL0dzs7NbKyZrTSzbDP7SSnvJ5vZW2a20MyWmtk1p1h/rTW8YyrPXz+EXYVFXPzIDLJz98W6JBGpwcK5srgd6OruPd29d/DVJ9SHzCweeAgYB/QAJplZjxKbfR9Y5u59gdHAn82s7il9g1psQEYT/nHjMI4ccy59dAZLNu+OdUkiUkOFExabgPL8FRoMZLv7WncvAl4CJpTYxoFGZmZAQ2AnoAcJTkH3Vo35541DqVcnnklTZzJr7Y5YlyQiNVA4YbEW+NzM7jKzO46/wvhcGwJBc1xOcF1xDwLdgS3AYuB2dz9WckdmNsXM5prZ3Ly8vDAOXbt0SGvIyzcNo3njRK56cjYfL9se65JEpIYJJyw2ErhfURdoVOwVipWyzkss/xewAGgN9AMeNLPG3/qQ+1R3z3L3rLS0tDAOXfu0TqnPyzcNp1vLRtz4/DxenZcT65JEpAZJCLWBu/8CwMwaBRY93DupOUB6seW2BK4girsG+L27O5BtZuuAbsDsMI8hxTRtUJcXbhjKjc/N5ccvL2RH4SGmjOoY67JEpAYIpzdULzP7BlgCLDWzeWbWM4x9zwE6m1n74E3ricCbJbbZCJwePE4LoCuBZi8pp4aJCTx59SDO7tOK3767gt+8s4xjx0pe0ImInJqQVxbAVOAOd/8MwMxGA48Bw8v6kLsfMbNbgQ+AeOBJd19qZjcF338E+BXwtJktJtBsdae755f3y0hAYkI8D0zsT2qDujz25Try9xXxhwv7UDdBz2CKSPmEExYNjgcFgLt/bmYNwtm5u78LvFti3SPFft8CnBlmrXIK4uKMn5/bk7RGidzz4Sry9x3i4SsG0jAxnH/kIiL/KazeUGb2UzPLDL7+D1gX6cKk4syMW7/bmT9e1Ifpa3Zw6aMaHkREyiecsLgWSANeA14P/q4nrauRS7LSeXxyFuvyCzn/b9P1tLeInLKQYeHuu9z9B+4+wN37u/vt7r4rGsVJ5RnTtTkvTRnKoSNHueBvX+vhPRE5JScNCzP7a/DnW2b2ZslX9EqUytKnbQqv3zKCtEaJXPnEbN5YsDnWJYlINVHW3c7ngj/viUYhEh3pTZN49ebhTHluHre/tICcXQe4ZXRHAiOuiIiU7qRXFu4+L/hrP3f/oviLwNPWUk2lJNXluesGM6Ffa/70wUr+55VFFB351igrIiL/Fs4N7smlrLu6kuuQKEtMiOevl/bjB6d35uV5OUx+cja792uqVhEpXVn3LCaZ2VtA+xL3Kz4DdHe0BjAz7jijC3+5tC/zNuzi/Ie/Zl1+YazLEpEqqKx7FtOBrUAq8Odi6/cCiyJZlETX+f3b0iYliRufm8t5D33Nw1cMYHjH1FiXJSJViAXG8Ks+srKyfO7cubEuo0bauGM/1z0zh3X5hfzqvF5MGqzZc0VqCjOb5+5Z5f18OAMJDjWzOWa2z8yKzOyome0p7wGl6spolsSrtwxnRKdU7nptMT9/cylHjurGt4iEd4P7QWASsBqoD1wPPBDJoiR2GterwxOTs7h2RHuenr6eq5+aQ8H+oliXJSIxFtYwpO6eDcS7+1F3fwoYE9myJJYS4uP42Tk9+ONFfZi9bifnPfQ12bl7Y12WiMRQOGGxPzgfxQIz+6OZ/QgIa9RZqd4uyUrnxSlD2HfoKOc9NJ2PNF2rSK0VTlhcGdzuVqCQwOx3F0ayKKk6BrZrypu3jqBDWgNueHYu9328WpMpidRCZYaFmcUDv3H3g+6+x91/4e53BJulpJZonVKff944jAv6t+EvH6/ipufnsfegHuATqU3KDAt3PwqkBZuhpBarVyeeP1/Sl5+O78EnK3KZoPsYIrVKOM1Q64GvgxMg3XH8FeG6pAoyM64b2Z7nrxvCngOHmfDg17y3eGusyxKRKAgnLLYAbwe3bVTsJbXUsI7NeOu2kXRu0YibX5jP795drucxRGq4kBMyu/svAMysUWDRNc2a0Cq5Pv+4cSi/fGsZj05by4JNBTxwWX+aN6oX69JEJALCeYK7l5l9AywBlprZPDPrGfnSpKpLTIjnN+f35t5L+rIwp4Cz7/+K2et2xrosEYmAcJqhpgJ3uHs7d28H/Bh4LLJlSXVywYC2/Ov7I2iYmMCkx2byyBdr1L1WpIYJJywauPtnxxfc/XP0UJ6U0K1lY968dQRje7bk9++t4IZn52qYEJEaJJywWBvsCZUZfP0fsC7ShUn106heHR68rD+/OLcn01bncfb9XzF/465YlyUilSCcsLgWSANeA14P/n5NJIuS6svMmDw8k1duGo4ZXPLIDKZOU7OUSHWn+SwkYnYfOMxPXl3Ee0u2MbprGn++uC/NGibGuiyRWqmi81mcNCyCU6qeNEnc/dzyHrQiFBbVi7vz/MwN/Oqd5aTUr8NfL+3H8E6ahU8k2ioaFmU9Z3FPeXcqcpyZceWwTAa2a8ptL87n8idmccvojvzwe12oEx/WCPkiUgWE1QwVHBuqG4ErjZXuHrNuLrqyqL72Fx3hl28t46U5m+ifkcJ9l/Yno1lSrMsSqRWiMa3q2cAa4H4Cs+Zlm9m48h5Qaq+kugn8/sI+PHhZf7Jz93HW/V/y6rwcqtt9M5HaKJx2gD8DY9x9tLufRmCWvL9Etiypycb3ac37PxxFj1aN+fHLC7ntxW/YvV9DnotUZeGERW6J+SvWArkRqkdqiTYp9XlxylD++8wuvL9kG2Pvm8b07PxYlyUiJxFOWCw1s3fN7Gozmwy8BcwxswvM7IKyPmhmY81spZllm9lPTrLNaDNbYGZLzeyLcnwHqabi44xbv9uZV28eTv068Vz2+Cx+/fYyDh4+GuvSRKSEkDe4zeypMt52d7/2JJ+LB1YBZwA5wBxgkrsvK7ZNCjAdGOvuG82subuXedWiG9w10/6iI/z23eU8P3MjXVo05N5L+tGrTXKsyxKpMSLZdRYAd//W09pmVjeMHlGDgWx3Xxv8zEvABGBZsW0uA15z943BY6l5q5ZKqpvAr8/rzendW3DnK4s476Gvuf30ztw8uiMJ6mIrEnPh9Ib63Mwyiy0PInCVEEobYFOx5ZzguuK6AE2Cx5hnZleFsV+pwcZ0bc6HPxrFuN6t+PNHq7jw4emavlWkCgjnf9l+B7xvZreY2W8IDFkezthQVsq6km1eCcBA4Gzgv4CfmlmXb+3IbIqZzTWzuXl5eWEcWqqzlKS6PDCpPw9e1p+NO/dz1v1f8egXaziq8aVEYiZkWLj7B8BNwH0EBhUc5+7zw9h3DpBebLktgSlaS27zvrsXuns+MA3oW0oNU909y92z0tLSwji01ATj+7Tmwx+dxuguafzuvRVc/Mh0snM1UaNILITTDPVT4AFgFPBz4PPgg3qhzAE6m1n74BPgE4E3S2zzBvAdM0swsyRgCLD8FOqXGi6tUSKPXjmQ+yb2Y01eIWfd/yUPf75Gc36LRFk4zVCpwGB3n+HujxJoLvphqA+5+xHgVuADAgHwT3dfamY3mdlNwW2WA+8Di4DZwOPuvqR8X0VqKjNjQr82fHTHKMZ0TeMP76/gwoens3Kb7mWIREu4Y0PVBzLcfWXkSyqbus7Wbu7OO4u38rM3lrL34GFuGd2JW8Z0JDEhPtaliVRp0Rgb6hxgAYErAMysn5mVbE4SiQozY3yf1nx8x2mc3bsV932ymvGakU8k4sJphvo5gWcmCgDcfQHQPoI1iYTUtEFd/jqxP09dPYjCQ0e48OHp3P3GEvYe1BhTIpEQTlgccffdJdapD6NUCWO6NefDO05j8rBMnp25gTPuncYHS7fFuiyRGiecsFhiZpcB8WbW2cweIDBEh0iV0DAxgZ+f25PXbxlBSlIdbnxuHjc8O5ctBQdiXZpIjRFOWNwG9AQOAX8HdhNGbyiRaOuXnsJbt43krnHd+Gp1Pt+79wse/3KtutmKVIKwekNVJeoNJeHYtHM/d7+5lE9X5NK9VWN+fV5PBrZrGuuyRGIm4r2hRKqj9KZJPDE5i0euGEDB/iIufHgG//PKQnYWxmxGYJFqTWEhNZaZMbZXKz6+4zRuPK0Dr83fzJh7Pue5mRs0zpTIKTppWJjZH4I/L45eOSKVr0FiAneN6867t3+H7q0a8dN/LWHCQ18xb4OezRAJV1lXFmeZWR3grmgVIxJJXVo04sUbhnL/pP7k7T3EhQ9P545/LiB3z8FYlyZS5ZU1+dH7QD7QwMz2EBhy3I//dPfGUahPpFKZGef2bc3p3ZrzwKfZPPnVOj5Yso3bTu/MNSMyNWyIyEmEM63qG+4+IUr1hKTeUFKZ1ucX8ut3lvHx8lwymyXxv2f34Hvdm2NW2nQsItVXxHtDufsEM2thZuODL00oITVGZmoDHp88iGeuHUxCfBw3PDuXK5+YzYpte2JdmkiVEs5AghcTGD78YuASYLaZXRTpwkSi6bQuabx3+3f4+Tk9WLx5N2fd9yV3vbaYvL2HYl2aSJUQTjPUQuAMd88NLqcBH7v7t2a0iwY1Q0mkFewv4r5PVvPcjA0kJsRxy5hOXDeyPfXq6H6GVF/ReCgv7nhQBO0I83Mi1VJKUl3uPqcnH/5oFCM6pfKnD1Yy5p7PeWVejp7PkFornD/675vZB2Z2tZldDbwDvBvZskRir0NaQ6ZelcVLU4bSvFEi//3yQsY/8BVfrs6LdWkiURfuTHkXACMJdJud5u6vR7qwk1EzlMTCsWPO24u38qcPVrBp5wFGdkrlzrHd6N02OdaliYSlos1QGkhQ5BQcOnKUF2Zu5IFPV7Nr/2HO6duaH5/RhczUBrEuTaRMCguRGNh78DBTp63l8S/XUXT0GJcOSucH3+1My+R6sS5NpFQKC5EYyt17kIc+zebvszcSZ8ZVw9px8+hONG1QN9alifyHiIeFmY0H3nX3KjGDjMJCqqJNO/fzl49X8a9vNlO/TjzXjWzPdd/pQHL9OrEuTQSITtfZicBqM/ujmXUv74FEarL0pknce0k/PvzRKEZ3bc79n2bznT98ygOfrGbvwcOxLk+kwsLtDdUYmARcQ2AwwaeAF919b2TL+zZdWUh1sGTzbv768Wo+Xr6dlKQ6TBnVgcnDMmmQWNbYnSKRE7V7FmaWClxBYP7t5UAn4H53f6C8By8PhYVUJ4tyCrj3o1V8vjKPJkl1uP47HZg8PJOGCg2JsmjcsziXwBVFR+A54Bl3zzWzJGC5u7cr78HLQ2Eh1dGCTQXc9/EqPluZR0pSHa4b0Z7JIzJpXE/3NCQ6ohEWzwKPu/u0Ut473d0/Ke/By0NhIdXZgk0F3P/Jaj5dkUujeglcMzyTa0e2JyVJvacksqJxg3tryaA4PuVqtINCpLrrl57Ck1cP4u3bRjK8YzPu/zSbEb//lN+9u5zcvZqxT6qucK4s5rv7gBLrFrl7n4hWdhK6spCaZMW2PTz8+RreWriFhPg4Ls1KZ8qoDqQ3TYp1aVLDRKwZysxuBm4hcK8iu9hbjYCv3f2K8h60IhQWUhOtzy/k0WlreGVeDsccxvdpxU2ndaR7K81eLJUjkmGRDDQBfgf8pNhbe919Z3kPWFEKC6nJtu0+yJNfr+OFmRsoLDrK6K5pTBnVgWEdmmmqV6mQSIZFY3ffY2ZNS3s/VoGhsJDaYPf+wzw3cz1PT19P/r4i+rRNZsqoDozt2ZKEeE0nI6cukmHxtruPN7N1BB7EK/6/Ne7uHcp70IpQWEhtcvDwUV6dn8PjX65jXX4hbZvU59oR7blkULqe1ZBTUqUHEjSzscB9QDyB7re/P8l2g4CZwKXu/kpZ+1RYSG109Jjz8fLtPP7lWuas30WjeglcNjiDycMzaZ1SP9blSTUQySuLAaW+EeTu80MUFg+sAs4AcoA5wCR3X1bKdh8BB4EnFRYiZftm4y4e/2od7y/ZBsC4Xi25dmR7BmQ0iXFlUpVVNCzKuo79cxnvOfDdEPseDGS7+1oAM3sJmAAsK7HdbcCrwKAQ+xMRoH9GEx66rAmbCw7wzPT1vDh7I28v2krf9BSuHZHJuF6tqJug+xpSuSLWDGVmFwFj3f364PKVwBB3v7XYNm2AvxMInieAt0u7sjCzKcAUgIyMjIEbNmyISM0i1VHhoSO8Oj+Hp79ez9r8QtIaJXLZ4AwuH5JB88aajEkCInZlYWbfdfdPg/Nvf4u7vxaqttI+VmL5r8Cd7n60rG6B7j4VmAqBZqgQxxWpVRokJnDVsEyuGNKOL1bn8cz09dz3yWoe+iybs3q34sph7chq10Rdb6VCymqGOg34FDinlPccCBUWOUB6seW2wJYS22QBLwX/JU4FzjKzI+7+rxD7FpES4uKMMV2bM6Zrc9bnF/LsjA28PG8Tby7cQreWjbhyWDvO69dGw6RLuUSyGSqBwA3u04HNBG5wX+buS0+y/dOcpBmqON3gFgnf/qIjvLFgC8/O2MDyrXtomJjA+f3bcMXQdnRt2SjW5UkURfIG9/EDNAPuBkYSuKL4Cvilu+8o63PufsTMbgU+INB19kl3X2pmNwXff6S8RYtIeJLqJjBpcAYTB6Uzf+MuXpi5kX/M3cRzMzeQ1a4JkwZncHafVtSrEx/rUqWKC2cgwY+AacDzwVWXA6Pd/XsRrq1UurIQqZidhUW8Mm8TL87exLr8QhrXS+CCAW2ZNDhDVxs1WDTms5jn7gNLrJtbkYNWhMJCpHK4OzPX7uTvszfywZJtFB09Rr/0FCYOSmd839Z6QryGiUZY3APMBf4ZXHUR0NPd7y7vQStCYSFS+XYWFvH6N5t5afZGVufuI6luPGf3bsUlg9LVk6qGiOQT3Hs5MSZUA+BY8K04YJ+7x2TsZIWFSOS4O/M3FvDy3E28tXALhUVHaZ/agIsGtuX8/m00tEg1VqXHhooEhYVIdOwvOsI7i7byyrwcZq3biRmM7JTKRQPbcmaPltSvq5vi1UlUwsLMmgCdgX8/DlranNzRoLAQib4NOwp5df5mXp2Xw+aCAzRMTOCs3i05v39bhrRvSlycmqmqumjcs7geuJ3AQ3ULgKHADHcPNTZURCgsRGLn2DFn1rqdvDY/h3cXb6Ww6ChtUuozoV9rzu/fhs4t1JuqqopGWCwmMMjfTHfvZ2bdgF+4+6XlPWhFKCxEqob9RUf4aNl2Xv9mM1+uzufoMadHq8ac17815/RtTatk3d+oSqIRFnPcfZCZLSAwEOAhM1vg7v3Ke9CKUFiIVD15ew/x9qIt/GvBFhZuKsAMBmc25Zy+rTmrdyuaNqgb6xJrvWiExevANcAPCYwOuwuo4+5nlfegFaGwEKna1ucX8saCLby5cDNr8gpJiDNGdk5lfJ/WnNmzBY3r1Yl1ibVSVHtDmdlpQDLwvrsXlfegFaGwEKke3J3lW/fy5sItvLVwC5sLDlA3Po5RXdIY36cVp3dvTiMFR9REqzfUAE6MDfV1qFnyIklhIVL9uDsLNhXw9qKtvLNoK9v2HKRuQhyjOqdxdp+WnN5dVxyRFo1mqJ8BF3NiSPLzgJfd/dflPWhFKCxEqrdjx5xvNu3inUXbeHdxIDjqxBsjO6UyrlcrzujRgia6x1HpohEWy4H+7n4wuFwfmO/u3ct70IpQWIjUHIHgKOD9JVt5d/E2NhccID7OGNK+KWN7teTMHi1pmazZ/ipDNMLiPWCSuxcEl1OA5919fHkPWhEKC5Gayd1ZumUP7y/ZxntLtrImrxCAvm2TObNnS87s0YJOzRtqnKpyiuTYUA8QuEeRQeA5i4+Cy2cAX7n7xPIetCIUFiK1Q3buXj5ctp0Pl25nwaYCANo1S+KM7i34Xo8WZLVrQkJ8XIyrrD4iGRaTy/qguz9T3oNWhMJCpPbZtvsgHy/fzkfLtjNjzQ6Kjh4juX4dxnRN4/TuLRjVJY3k+rpBXpZo9YaqC3QJLq5098PlPWBFKSxEare9Bw/z5ep8Pl6+nc9W5LJr/2ES4oyszCac3q0FY7o1p2NaAzVXlRCNexajgWeA9QSGK08HJmsgQRGJtaPHnPkbd/Hpilw+W5HLim17AchomsSYrmmM7tacoe2baYRcojRTHnCZu68MLncBXiw5e160KCxE5GRydu3n85V5fLYil6/X5HPw8DESE+IY0qEZo7ukMapLWq296ohGWCxy9z6h1kWLwkJEwnHw8FFmrdvJFyvz+HxVLmuDvavapNRnVJc0TuuSyrCOqbXmXkc0wuIpArPkPRdcdTmQ4O7XlPegFaGwEJHy2LRzP1+symPaqjymr9nBvkNHiDPol57CyM5pfKdzKv3SU6hTQ3tYRSMsEoHvExjuw4BpwN/c/VB5D1oRCgsRqajDR4+xYFMBX67KY9rqfBblFHDMoUHdeIZ2aMbwTqmM7JRKlxY157mOiIaFmcUBi9y9V3kPUNkUFiJS2XbvP8yMtfl8lZ3PV6vzWb9jPwCpDRMZ1rEZw4OvjKZJ1TY8KhoWCWW96e7HzGyhmWW4+8byHkREpCpLTqrD2F6tGNurFQCbCw7wdXY+07Pzmb5mB28t3AJA6+R6DO3YjGEdmjG0QzPSmybFsuyoCqcZ6lMCT3DPBgqPr3f3cyNbWul0ZSEi0eTurMkrZMaafGas3cHMtTvZWRiYoaFNSn2GdGjK0PbNGNKhaZW+8ojGPYvTSlvv7l+U96AVobAQkVg6dsxZlbuXmWt2MGvdTmatOxEeLRonMrh9MwZnNmFQ+6Z0ad6IuLiqER6RHO6jHnAT0AlYDDzh7kfKe6DKorAQkarE3Vmdu49Z63Yye91OZq3dQe7eQP+f5Pp1yGrXhKzMpgzKbELvtskkJsTmAcFI3rN4BjgMfAmMA3oAt5f3QCIiNZGZ0aVFI7q0aMSVQ9vh7mzaeYDZ63cyd/1OZq/fyScrcgGoGx9H77bJZLVrwoB2TRjYrgmpDRNj/A3CU9aVxWJ37x38PQGY7e4DollcaXRlISLVzY59h5i3YRdzN+xi7tEArIUAAAmWSURBVPqdLNm8h6Kjx4DA0CQD2zVhQEYK/TOa0K1lo4iMphvJK4t/Dxbo7keq6k0bEZGqrlnDxMCcHD1bAoGny5ds3s28DbuYv3EXX2Xn8/o3mwGoXyee3m2T6Z+RQv/0FPqlN6kSE0CVdWVxlBO9nwyoD+wP/u7u3jgqFZagKwsRqWncnZxdB/hmUwHfbNzF/I0FLN9y4uqjZeN69E1Ppk/bFPqlp9C7bfIpz1kesSsLd9cwjSIiUWBmpDdNIr1pEuf2bQ3AoSNHWbZlDws2FbBgUwGLcnbzwdLt//5Mh9QG9GkbCJA+bZPp0boxSXXLfHSuQiK3Z8DMxgL3AfHA4+7++xLvXw7cGVzcB9zs7gsjWZOISHWQmBBP/4wm9M9o8u91BfuLWJSzm0U5BSzM2c2MtTv414LAA4NxBh3TGtK7TTK92iTTu20yPSsxQMKa/KhcOzaLB1YRmIY1B5hDYC7vZcW2GQ4sd/ddZjYO+Lm7Dylrv2qGEhE5YfuegyzO2c3izYEQWbJlD3nBrrt3n9ODa0a0ByI83EcFDQay3X0tgJm9BEwA/h0W7j692PYzgbYRrEdEpMZp0bgeLXrU43s9Wvx73fY9B1myeTddWzaqtONEMizaAJuKLecAZV01XAe8V9obZjYFmAKQkZFRWfWJiNRILRrXo0Xjyu1BFcmB20vra1tqm5eZjSEQFneW9r67T3X3LHfPSktLq8QSRUQkHJG8ssghMF/3cW2BLSU3MrM+wOPAOHffEcF6RESknCJ5ZTEH6Gxm7c2sLjAReLP4BmaWAbwGXOnuqyJYi4iIVEDEriyCT33fCnxAoOvsk+6+1MxuCr7/CPAzoBnwt+AT4kcqcrdeREQiI2JdZyNFXWdFRE5dRbvO1syZyUVEpFIpLEREJCSFhYiIhKSwEBGRkBQWIiISksJCRERCUliIiEhICgsREQlJYSEiIiEpLEREJCSFhYiIhKSwEBGRkBQWIiISksJCRERCUliIiEhICgsREQlJYSEiIiEpLEREJCSFhYiIhKSwEBGRkBQWIiISksJCRERCUliIiEhICgsREQlJYSEiIiEpLEREJCSFhYiIhKSwEBGRkBQWIiISksJCRERCUliIiEhICgsREQlJYSEiIiFFNCzMbKyZrTSzbDP7SSnvm5ndH3x/kZkNiGQ9IiJSPhELCzOLBx4CxgE9gElm1qPEZuOAzsHXFODhSNUjIiLlF8kri8FAtruvdfci4CVgQoltJgDPesBMIMXMWkWwJhERKYeECO67DbCp2HIOMCSMbdoAW4tvZGZTCFx5ABwysyWVW2q1lQrkx7qIKkLn4gSdixN0Lk7oWpEPRzIsrJR1Xo5tcPepwFQAM5vr7lkVL6/607k4QefiBJ2LE3QuTjCzuRX5fCSboXKA9GLLbYEt5dhGRERiLJJhMQfobGbtzawuMBF4s8Q2bwJXBXtFDQV2u/vWkjsSEZHYilgzlLsfMbNbgQ+AeOBJd19qZjcF338EeBc4C8gG9gPXhLHrqREquTrSuThB5+IEnYsTdC5OqNC5MPdv3SIQERH5D3qCW0REQlJYiIhISNUqLEINH1KTmVm6mX1mZsvNbKmZ3R5c39TMPjKz1cGfTWJdazSYWbyZfWNmbweXa+t5SDGzV8xsRfDfjWG1+Fz8KPjfxhIze9HM6tWmc2FmT5pZbvHn0Mr6/mZ2V/Bv6Uoz+69Q+682YRHm8CE12RHgx+7eHRgKfD/4/X8CfOLunYFPgsu1we3A8mLLtfU83Ae87+7dgL4EzkmtOxdm1gb4AZDl7r0IdKqZSO06F08DY0usK/X7B/92TAR6Bj/zt+Df2JOqNmFBeMOH1FjuvtXd5wd/30vgj0IbAufgmeBmzwDnxabC6DGztsDZwOPFVtfG89AYGAU8AeDuRe5eQC08F0EJQH0zSwCSCDyzVWvOhbtPA3aWWH2y7z8BeMndD7n7OgI9UgeXtf/qFBYnGxqk1jGzTKA/MAtocfzZlODP5rGrLGr+CvwPcKzYutp4HjoAecBTwSa5x82sAbXwXLj7ZuAeYCOB4YJ2u/uH1MJzUcLJvv8p/z2tTmER1tAgNZ2ZNQReBX7o7ntiXU+0mdl4INfd58W6liogARgAPOzu/YFCanYzy0kF2+InAO2B1kADM7sitlVVaaf897Q6hUWtHxrEzOoQCIoX3P214Ortx0fqDf7MjVV9UTICONfM1hNoivyumT1P7TsPEPhvIsfdZwWXXyEQHrXxXHwPWOfuee5+GHgNGE7tPBfFnez7n/Lf0+oUFuEMH1JjmZkRaJte7u73FnvrTWBy8PfJwBvRri2a3P0ud2/r7pkE/h341N2voJadBwB33wZsMrPjo4meDiyjFp4LAs1PQ80sKfjfyukE7uvVxnNR3Mm+/5vARDNLNLP2BOYUml3WjqrVE9xmdhaB9urjw4f8JsYlRY2ZjQS+BBZzoq3+/xG4b/FPIIPAfzAXu3vJm1w1kpmNBv7b3cebWTNq4Xkws34EbvTXBdYSGDInjtp5Ln4BXEqg5+A3wPVAQ2rJuTCzF4HRBIZl3w7cDfyLk3x/M/tf4FoC5+uH7v5emfuvTmEhIiKxUZ2aoUREJEYUFiIiEpLCQkREQlJYiIhISAoLEREJSWEhchJm9r/BUUwXmdkCMxtiZj80s6RY1yYSbeo6K1IKMxsG3AuMdvdDZpZK4FmG6QRGNs2PaYEiUaYrC5HStQLy3f0QQDAcLiIw7tBnZvYZgJmdaWYzzGy+mb0cHLsLM1tvZn8ws9nBV6fg+ouD8y0sNLNpsflqIqdOVxYipQj+0f+KwFDXHwP/cPcvgmNSZbl7fvBq4zVgnLsXmtmdQKK7/zK43WPu/hszuwq4JPik+WJgrLtvNrOU4JDiIlWerixESuHu+4CBwBQCw4D/w8yuLrHZUAITcX1tZgsIjL3Trtj7Lxb7OSz4+9fA02Z2A4Fha0SqhYRYFyBSVbn7UeBz4PPgFcHkEpsY8JG7TzrZLkr+7u43mdkQApM3LTCzfu6+o3IrF6l8urIQKYWZdTWzzsVW9QM2AHuBRsF1M4ERxe5HJJlZl2KfubTYzxnBbTq6+yx3/xmQz38OEy1SZenKQqR0DYEHzCyFwKic2QSapCYB75nZVncfE2yaetHMEoOf+z9gVfD3RDObReB/yo5fffwpGEJGYE7khVH5NiIVpBvcIhFQ/EZ4rGsRqQxqhhIRkZB0ZSEiIiHpykJEREJSWIiISEgKCxERCUlhISIiISksREQkpP8PV1YFl24J5+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "# Discount Factor\n",
    "GAMMA = 0.9\n",
    "\n",
    "# Define epsilon greedy behaviour with 3 parameters.\n",
    "# Note we want to explore exclusively initially.\n",
    "EPS_START = 1.2\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 50.0\n",
    "\n",
    "# Plot what our epsilon values look like.\n",
    "plot_eps(100,EPS_START,EPS_END,EPS_DECAY)\n",
    "\n",
    "# How often do we update our policy network parameters (in steps)\n",
    "TARGET_UPDATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a2471c1dd45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Initialize the environment and state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mTotalReward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    TotalReward=0\n",
    "    state, reward, done, _ = env.step(1)\n",
    "    state = torch.from_numpy(np.cast['float32'](state)).unsqueeze(0).to(device)\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        #print(action)\n",
    "\n",
    "        env.render()\n",
    "        next_state, reward, done, _ = env.step(action.item())\n",
    "        TotalReward+= reward\n",
    "        next_state = torch.from_numpy(np.cast['float32'](next_state)).unsqueeze(0).to(device)\n",
    "        reward = torch.tensor([reward], device=device,dtype=torch.float32)\n",
    "\n",
    "        if not done:\n",
    "            next_state = next_state\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            reward_values.append(TotalReward)\n",
    "            plot_reward()\n",
    "            break\n",
    "            \n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        # Update the target network, copying all weights and biases in DQN\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "plot_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(168.3635, grad_fn=<MseLossBackward>),\n",
       " tensor(167.8331, grad_fn=<MseLossBackward>),\n",
       " tensor(167.2818, grad_fn=<MseLossBackward>),\n",
       " tensor(166.7374, grad_fn=<MseLossBackward>),\n",
       " tensor(166.1365, grad_fn=<MseLossBackward>),\n",
       " tensor(165.5999, grad_fn=<MseLossBackward>),\n",
       " tensor(155.2245, grad_fn=<MseLossBackward>),\n",
       " tensor(164.2688, grad_fn=<MseLossBackward>),\n",
       " tensor(163.6036, grad_fn=<MseLossBackward>),\n",
       " tensor(162.9236, grad_fn=<MseLossBackward>),\n",
       " tensor(162.2370, grad_fn=<MseLossBackward>),\n",
       " tensor(161.4879, grad_fn=<MseLossBackward>),\n",
       " tensor(160.6542, grad_fn=<MseLossBackward>),\n",
       " tensor(159.8440, grad_fn=<MseLossBackward>),\n",
       " tensor(159.1022, grad_fn=<MseLossBackward>),\n",
       " tensor(158.0455, grad_fn=<MseLossBackward>),\n",
       " tensor(157.4305, grad_fn=<MseLossBackward>),\n",
       " tensor(156.2281, grad_fn=<MseLossBackward>),\n",
       " tensor(155.6113, grad_fn=<MseLossBackward>),\n",
       " tensor(154.6444, grad_fn=<MseLossBackward>),\n",
       " tensor(134.9918, grad_fn=<MseLossBackward>),\n",
       " tensor(152.8094, grad_fn=<MseLossBackward>),\n",
       " tensor(143.1017, grad_fn=<MseLossBackward>),\n",
       " tensor(142.0054, grad_fn=<MseLossBackward>),\n",
       " tensor(150.0670, grad_fn=<MseLossBackward>),\n",
       " tensor(149.2559, grad_fn=<MseLossBackward>),\n",
       " tensor(148.0619, grad_fn=<MseLossBackward>),\n",
       " tensor(147.5247, grad_fn=<MseLossBackward>),\n",
       " tensor(137.1906, grad_fn=<MseLossBackward>),\n",
       " tensor(144.6177, grad_fn=<MseLossBackward>),\n",
       " tensor(145.3052, grad_fn=<MseLossBackward>),\n",
       " tensor(136.2369, grad_fn=<MseLossBackward>),\n",
       " tensor(144.1494, grad_fn=<MseLossBackward>),\n",
       " tensor(142.0456, grad_fn=<MseLossBackward>),\n",
       " tensor(143.0461, grad_fn=<MseLossBackward>),\n",
       " tensor(125.5023, grad_fn=<MseLossBackward>),\n",
       " tensor(142.2555, grad_fn=<MseLossBackward>),\n",
       " tensor(131.8207, grad_fn=<MseLossBackward>),\n",
       " tensor(116.7474, grad_fn=<MseLossBackward>),\n",
       " tensor(140.9588, grad_fn=<MseLossBackward>),\n",
       " tensor(133.2124, grad_fn=<MseLossBackward>),\n",
       " tensor(139.8524, grad_fn=<MseLossBackward>),\n",
       " tensor(139.4057, grad_fn=<MseLossBackward>),\n",
       " tensor(138.8285, grad_fn=<MseLossBackward>),\n",
       " tensor(122.0205, grad_fn=<MseLossBackward>),\n",
       " tensor(137.5027, grad_fn=<MseLossBackward>),\n",
       " tensor(127.9328, grad_fn=<MseLossBackward>),\n",
       " tensor(135.9315, grad_fn=<MseLossBackward>),\n",
       " tensor(135.5138, grad_fn=<MseLossBackward>),\n",
       " tensor(128.7058, grad_fn=<MseLossBackward>),\n",
       " tensor(133.9098, grad_fn=<MseLossBackward>),\n",
       " tensor(125.0422, grad_fn=<MseLossBackward>),\n",
       " tensor(132.9774, grad_fn=<MseLossBackward>),\n",
       " tensor(123.8237, grad_fn=<MseLossBackward>),\n",
       " tensor(131.6317, grad_fn=<MseLossBackward>),\n",
       " tensor(105.4830, grad_fn=<MseLossBackward>),\n",
       " tensor(130.1117, grad_fn=<MseLossBackward>),\n",
       " tensor(129.6402, grad_fn=<MseLossBackward>),\n",
       " tensor(128.9030, grad_fn=<MseLossBackward>),\n",
       " tensor(128.1252, grad_fn=<MseLossBackward>),\n",
       " tensor(127.0602, grad_fn=<MseLossBackward>),\n",
       " tensor(126.8332, grad_fn=<MseLossBackward>),\n",
       " tensor(118.6570, grad_fn=<MseLossBackward>),\n",
       " tensor(117.1441, grad_fn=<MseLossBackward>),\n",
       " tensor(122.0162, grad_fn=<MseLossBackward>),\n",
       " tensor(123.5862, grad_fn=<MseLossBackward>),\n",
       " tensor(113.8912, grad_fn=<MseLossBackward>),\n",
       " tensor(122.3427, grad_fn=<MseLossBackward>),\n",
       " tensor(112.5470, grad_fn=<MseLossBackward>),\n",
       " tensor(120.9740, grad_fn=<MseLossBackward>),\n",
       " tensor(115.9522, grad_fn=<MseLossBackward>),\n",
       " tensor(119.4695, grad_fn=<MseLossBackward>),\n",
       " tensor(109.5193, grad_fn=<MseLossBackward>),\n",
       " tensor(116.1237, grad_fn=<MseLossBackward>),\n",
       " tensor(101.8188, grad_fn=<MseLossBackward>),\n",
       " tensor(104.7168, grad_fn=<MseLossBackward>),\n",
       " tensor(109.4793, grad_fn=<MseLossBackward>),\n",
       " tensor(105.0178, grad_fn=<MseLossBackward>),\n",
       " tensor(109.2510, grad_fn=<MseLossBackward>),\n",
       " tensor(112.4724, grad_fn=<MseLossBackward>),\n",
       " tensor(111.3713, grad_fn=<MseLossBackward>),\n",
       " tensor(96.5683, grad_fn=<MseLossBackward>),\n",
       " tensor(100.6396, grad_fn=<MseLossBackward>),\n",
       " tensor(108.8679, grad_fn=<MseLossBackward>),\n",
       " tensor(106.7445, grad_fn=<MseLossBackward>),\n",
       " tensor(103.4975, grad_fn=<MseLossBackward>),\n",
       " tensor(108.2122, grad_fn=<MseLossBackward>),\n",
       " tensor(107.4640, grad_fn=<MseLossBackward>),\n",
       " tensor(107.0270, grad_fn=<MseLossBackward>),\n",
       " tensor(96.4314, grad_fn=<MseLossBackward>),\n",
       " tensor(105.7061, grad_fn=<MseLossBackward>),\n",
       " tensor(95.2679, grad_fn=<MseLossBackward>),\n",
       " tensor(94.7298, grad_fn=<MseLossBackward>),\n",
       " tensor(96.8744, grad_fn=<MseLossBackward>),\n",
       " tensor(103.4220, grad_fn=<MseLossBackward>),\n",
       " tensor(69.2322, grad_fn=<MseLossBackward>),\n",
       " tensor(101.0671, grad_fn=<MseLossBackward>),\n",
       " tensor(102.2961, grad_fn=<MseLossBackward>),\n",
       " tensor(73.8274, grad_fn=<MseLossBackward>),\n",
       " tensor(101.7833, grad_fn=<MseLossBackward>),\n",
       " tensor(99.8355, grad_fn=<MseLossBackward>),\n",
       " tensor(93.8876, grad_fn=<MseLossBackward>),\n",
       " tensor(89.7378, grad_fn=<MseLossBackward>),\n",
       " tensor(99.3507, grad_fn=<MseLossBackward>),\n",
       " tensor(86.6388, grad_fn=<MseLossBackward>),\n",
       " tensor(93.9322, grad_fn=<MseLossBackward>),\n",
       " tensor(73.2974, grad_fn=<MseLossBackward>),\n",
       " tensor(84.1155, grad_fn=<MseLossBackward>),\n",
       " tensor(90.8427, grad_fn=<MseLossBackward>),\n",
       " tensor(86.0786, grad_fn=<MseLossBackward>),\n",
       " tensor(91.4620, grad_fn=<MseLossBackward>),\n",
       " tensor(85.9596, grad_fn=<MseLossBackward>),\n",
       " tensor(86.5816, grad_fn=<MseLossBackward>),\n",
       " tensor(87.4270, grad_fn=<MseLossBackward>),\n",
       " tensor(95.7886, grad_fn=<MseLossBackward>),\n",
       " tensor(75.8310, grad_fn=<MseLossBackward>),\n",
       " tensor(87.3181, grad_fn=<MseLossBackward>),\n",
       " tensor(76.6926, grad_fn=<MseLossBackward>),\n",
       " tensor(94.5427, grad_fn=<MseLossBackward>),\n",
       " tensor(86.3349, grad_fn=<MseLossBackward>),\n",
       " tensor(83.5744, grad_fn=<MseLossBackward>),\n",
       " tensor(83.1576, grad_fn=<MseLossBackward>),\n",
       " tensor(93.7380, grad_fn=<MseLossBackward>),\n",
       " tensor(70.5011, grad_fn=<MseLossBackward>),\n",
       " tensor(86.3375, grad_fn=<MseLossBackward>),\n",
       " tensor(87.9718, grad_fn=<MseLossBackward>),\n",
       " tensor(85.9142, grad_fn=<MseLossBackward>),\n",
       " tensor(70.6063, grad_fn=<MseLossBackward>),\n",
       " tensor(88.1851, grad_fn=<MseLossBackward>),\n",
       " tensor(79.2985, grad_fn=<MseLossBackward>),\n",
       " tensor(84.9551, grad_fn=<MseLossBackward>),\n",
       " tensor(83.5005, grad_fn=<MseLossBackward>),\n",
       " tensor(82.1743, grad_fn=<MseLossBackward>),\n",
       " tensor(82.0080, grad_fn=<MseLossBackward>),\n",
       " tensor(91.4075, grad_fn=<MseLossBackward>),\n",
       " tensor(83.2691, grad_fn=<MseLossBackward>),\n",
       " tensor(83.3142, grad_fn=<MseLossBackward>),\n",
       " tensor(67.5334, grad_fn=<MseLossBackward>),\n",
       " tensor(77.2144, grad_fn=<MseLossBackward>),\n",
       " tensor(82.2924, grad_fn=<MseLossBackward>),\n",
       " tensor(89.1651, grad_fn=<MseLossBackward>),\n",
       " tensor(80.7965, grad_fn=<MseLossBackward>),\n",
       " tensor(88.6351, grad_fn=<MseLossBackward>),\n",
       " tensor(84.9090, grad_fn=<MseLossBackward>),\n",
       " tensor(89.4256, grad_fn=<MseLossBackward>),\n",
       " tensor(83.8591, grad_fn=<MseLossBackward>),\n",
       " tensor(75.5474, grad_fn=<MseLossBackward>),\n",
       " tensor(76.8581, grad_fn=<MseLossBackward>),\n",
       " tensor(65.9292, grad_fn=<MseLossBackward>),\n",
       " tensor(80.8495, grad_fn=<MseLossBackward>),\n",
       " tensor(75.6270, grad_fn=<MseLossBackward>),\n",
       " tensor(76.9746, grad_fn=<MseLossBackward>),\n",
       " tensor(81.7383, grad_fn=<MseLossBackward>),\n",
       " tensor(69.3673, grad_fn=<MseLossBackward>),\n",
       " tensor(84.7377, grad_fn=<MseLossBackward>),\n",
       " tensor(75.1318, grad_fn=<MseLossBackward>),\n",
       " tensor(69.3012, grad_fn=<MseLossBackward>),\n",
       " tensor(83.3948, grad_fn=<MseLossBackward>),\n",
       " tensor(75.1637, grad_fn=<MseLossBackward>),\n",
       " tensor(72.2955, grad_fn=<MseLossBackward>),\n",
       " tensor(71.3321, grad_fn=<MseLossBackward>),\n",
       " tensor(62.5038, grad_fn=<MseLossBackward>),\n",
       " tensor(56.1282, grad_fn=<MseLossBackward>),\n",
       " tensor(74.0206, grad_fn=<MseLossBackward>),\n",
       " tensor(77.9630, grad_fn=<MseLossBackward>),\n",
       " tensor(57.3184, grad_fn=<MseLossBackward>),\n",
       " tensor(69.4662, grad_fn=<MseLossBackward>),\n",
       " tensor(74.4091, grad_fn=<MseLossBackward>),\n",
       " tensor(74.5746, grad_fn=<MseLossBackward>),\n",
       " tensor(69.7714, grad_fn=<MseLossBackward>),\n",
       " tensor(71.7453, grad_fn=<MseLossBackward>),\n",
       " tensor(68.5853, grad_fn=<MseLossBackward>),\n",
       " tensor(64.1650, grad_fn=<MseLossBackward>),\n",
       " tensor(75.0294, grad_fn=<MseLossBackward>),\n",
       " tensor(72.0115, grad_fn=<MseLossBackward>),\n",
       " tensor(61.0456, grad_fn=<MseLossBackward>),\n",
       " tensor(74.1167, grad_fn=<MseLossBackward>),\n",
       " tensor(67.4251, grad_fn=<MseLossBackward>),\n",
       " tensor(68.1119, grad_fn=<MseLossBackward>),\n",
       " tensor(67.1788, grad_fn=<MseLossBackward>),\n",
       " tensor(57.2304, grad_fn=<MseLossBackward>),\n",
       " tensor(58.4364, grad_fn=<MseLossBackward>),\n",
       " tensor(60.9169, grad_fn=<MseLossBackward>),\n",
       " tensor(70.4739, grad_fn=<MseLossBackward>),\n",
       " tensor(59.2971, grad_fn=<MseLossBackward>),\n",
       " tensor(60.4572, grad_fn=<MseLossBackward>),\n",
       " tensor(68.9868, grad_fn=<MseLossBackward>),\n",
       " tensor(57.4329, grad_fn=<MseLossBackward>),\n",
       " tensor(54.3687, grad_fn=<MseLossBackward>),\n",
       " tensor(60.1061, grad_fn=<MseLossBackward>),\n",
       " tensor(54.4063, grad_fn=<MseLossBackward>),\n",
       " tensor(68.8582, grad_fn=<MseLossBackward>),\n",
       " tensor(68.3675, grad_fn=<MseLossBackward>),\n",
       " tensor(70.8074, grad_fn=<MseLossBackward>),\n",
       " tensor(45.4243, grad_fn=<MseLossBackward>),\n",
       " tensor(63.1106, grad_fn=<MseLossBackward>),\n",
       " tensor(72.4414, grad_fn=<MseLossBackward>),\n",
       " tensor(72.1765, grad_fn=<MseLossBackward>),\n",
       " tensor(62.9681, grad_fn=<MseLossBackward>),\n",
       " tensor(62.8494, grad_fn=<MseLossBackward>),\n",
       " tensor(63.8814, grad_fn=<MseLossBackward>),\n",
       " tensor(63.8050, grad_fn=<MseLossBackward>),\n",
       " tensor(63.8799, grad_fn=<MseLossBackward>),\n",
       " tensor(51.6225, grad_fn=<MseLossBackward>),\n",
       " tensor(75.6466, grad_fn=<MseLossBackward>),\n",
       " tensor(71.3360, grad_fn=<MseLossBackward>),\n",
       " tensor(74.5582, grad_fn=<MseLossBackward>),\n",
       " tensor(75.8032, grad_fn=<MseLossBackward>),\n",
       " tensor(48.3645, grad_fn=<MseLossBackward>),\n",
       " tensor(69.6304, grad_fn=<MseLossBackward>),\n",
       " tensor(80.8260, grad_fn=<MseLossBackward>),\n",
       " tensor(75.3540, grad_fn=<MseLossBackward>),\n",
       " tensor(58.6634, grad_fn=<MseLossBackward>),\n",
       " tensor(80.4665, grad_fn=<MseLossBackward>),\n",
       " tensor(54.4795, grad_fn=<MseLossBackward>),\n",
       " tensor(71.9412, grad_fn=<MseLossBackward>),\n",
       " tensor(83.9447, grad_fn=<MseLossBackward>),\n",
       " tensor(84.7098, grad_fn=<MseLossBackward>),\n",
       " tensor(82.1583, grad_fn=<MseLossBackward>),\n",
       " tensor(75.7108, grad_fn=<MseLossBackward>),\n",
       " tensor(78.6111, grad_fn=<MseLossBackward>),\n",
       " tensor(81.3378, grad_fn=<MseLossBackward>),\n",
       " tensor(48.1076, grad_fn=<MseLossBackward>),\n",
       " tensor(75.2570, grad_fn=<MseLossBackward>),\n",
       " tensor(60.7361, grad_fn=<MseLossBackward>),\n",
       " tensor(64.8689, grad_fn=<MseLossBackward>),\n",
       " tensor(56.4908, grad_fn=<MseLossBackward>),\n",
       " tensor(69.6121, grad_fn=<MseLossBackward>),\n",
       " tensor(68.4399, grad_fn=<MseLossBackward>),\n",
       " tensor(78.2790, grad_fn=<MseLossBackward>),\n",
       " tensor(76.1304, grad_fn=<MseLossBackward>),\n",
       " tensor(71.3080, grad_fn=<MseLossBackward>),\n",
       " tensor(67.5205, grad_fn=<MseLossBackward>),\n",
       " tensor(72.7244, grad_fn=<MseLossBackward>),\n",
       " tensor(72.5763, grad_fn=<MseLossBackward>),\n",
       " tensor(67.4770, grad_fn=<MseLossBackward>),\n",
       " tensor(54.7995, grad_fn=<MseLossBackward>),\n",
       " tensor(69.7430, grad_fn=<MseLossBackward>),\n",
       " tensor(64.0946, grad_fn=<MseLossBackward>),\n",
       " tensor(64.7449, grad_fn=<MseLossBackward>),\n",
       " tensor(64.7039, grad_fn=<MseLossBackward>),\n",
       " tensor(69.0502, grad_fn=<MseLossBackward>),\n",
       " tensor(56.6907, grad_fn=<MseLossBackward>),\n",
       " tensor(69.8399, grad_fn=<MseLossBackward>),\n",
       " tensor(58.7420, grad_fn=<MseLossBackward>),\n",
       " tensor(61.2396, grad_fn=<MseLossBackward>),\n",
       " tensor(53.0538, grad_fn=<MseLossBackward>),\n",
       " tensor(50.7931, grad_fn=<MseLossBackward>),\n",
       " tensor(68.4289, grad_fn=<MseLossBackward>),\n",
       " tensor(61.8920, grad_fn=<MseLossBackward>),\n",
       " tensor(64.9472, grad_fn=<MseLossBackward>),\n",
       " tensor(68.8838, grad_fn=<MseLossBackward>),\n",
       " tensor(54.0510, grad_fn=<MseLossBackward>),\n",
       " tensor(55.4629, grad_fn=<MseLossBackward>),\n",
       " tensor(59.1903, grad_fn=<MseLossBackward>),\n",
       " tensor(68.0232, grad_fn=<MseLossBackward>),\n",
       " tensor(63.8168, grad_fn=<MseLossBackward>),\n",
       " tensor(61.8315, grad_fn=<MseLossBackward>),\n",
       " tensor(54.7939, grad_fn=<MseLossBackward>),\n",
       " tensor(65.8258, grad_fn=<MseLossBackward>),\n",
       " tensor(68.3659, grad_fn=<MseLossBackward>),\n",
       " tensor(67.1496, grad_fn=<MseLossBackward>),\n",
       " tensor(57.4166, grad_fn=<MseLossBackward>),\n",
       " tensor(51.9267, grad_fn=<MseLossBackward>),\n",
       " tensor(50.0310, grad_fn=<MseLossBackward>),\n",
       " tensor(61.1449, grad_fn=<MseLossBackward>),\n",
       " tensor(51.0234, grad_fn=<MseLossBackward>),\n",
       " tensor(43.7206, grad_fn=<MseLossBackward>),\n",
       " tensor(65.1548, grad_fn=<MseLossBackward>),\n",
       " tensor(52.9740, grad_fn=<MseLossBackward>),\n",
       " tensor(61.1418, grad_fn=<MseLossBackward>),\n",
       " tensor(67.1346, grad_fn=<MseLossBackward>),\n",
       " tensor(44.6944, grad_fn=<MseLossBackward>),\n",
       " tensor(63.9929, grad_fn=<MseLossBackward>),\n",
       " tensor(68.1429, grad_fn=<MseLossBackward>),\n",
       " tensor(50.1808, grad_fn=<MseLossBackward>),\n",
       " tensor(52.4120, grad_fn=<MseLossBackward>),\n",
       " tensor(45.5834, grad_fn=<MseLossBackward>),\n",
       " tensor(63.0853, grad_fn=<MseLossBackward>),\n",
       " tensor(53.8854, grad_fn=<MseLossBackward>),\n",
       " tensor(60.8481, grad_fn=<MseLossBackward>),\n",
       " tensor(44.3101, grad_fn=<MseLossBackward>),\n",
       " tensor(46.8021, grad_fn=<MseLossBackward>),\n",
       " tensor(55.9559, grad_fn=<MseLossBackward>),\n",
       " tensor(55.1245, grad_fn=<MseLossBackward>),\n",
       " tensor(45.8864, grad_fn=<MseLossBackward>),\n",
       " tensor(56.6268, grad_fn=<MseLossBackward>),\n",
       " tensor(52.9751, grad_fn=<MseLossBackward>),\n",
       " tensor(50.9577, grad_fn=<MseLossBackward>),\n",
       " tensor(49.5402, grad_fn=<MseLossBackward>),\n",
       " tensor(35.4021, grad_fn=<MseLossBackward>),\n",
       " tensor(39.0677, grad_fn=<MseLossBackward>),\n",
       " tensor(53.5461, grad_fn=<MseLossBackward>),\n",
       " tensor(41.6032, grad_fn=<MseLossBackward>),\n",
       " tensor(59.5848, grad_fn=<MseLossBackward>),\n",
       " tensor(49.8596, grad_fn=<MseLossBackward>),\n",
       " tensor(55.5569, grad_fn=<MseLossBackward>),\n",
       " tensor(47.7913, grad_fn=<MseLossBackward>),\n",
       " tensor(59.7799, grad_fn=<MseLossBackward>),\n",
       " tensor(39.0981, grad_fn=<MseLossBackward>),\n",
       " tensor(41.6814, grad_fn=<MseLossBackward>),\n",
       " tensor(54.0127, grad_fn=<MseLossBackward>),\n",
       " tensor(51.6061, grad_fn=<MseLossBackward>),\n",
       " tensor(38.4266, grad_fn=<MseLossBackward>),\n",
       " tensor(61.0847, grad_fn=<MseLossBackward>),\n",
       " tensor(54.8748, grad_fn=<MseLossBackward>),\n",
       " tensor(59.5735, grad_fn=<MseLossBackward>),\n",
       " tensor(42.5607, grad_fn=<MseLossBackward>),\n",
       " tensor(38.1900, grad_fn=<MseLossBackward>),\n",
       " tensor(51.5986, grad_fn=<MseLossBackward>),\n",
       " tensor(44.3876, grad_fn=<MseLossBackward>),\n",
       " tensor(52.5787, grad_fn=<MseLossBackward>),\n",
       " tensor(48.1279, grad_fn=<MseLossBackward>),\n",
       " tensor(45.7999, grad_fn=<MseLossBackward>),\n",
       " tensor(50.8411, grad_fn=<MseLossBackward>),\n",
       " tensor(53.2185, grad_fn=<MseLossBackward>),\n",
       " tensor(55.6078, grad_fn=<MseLossBackward>),\n",
       " tensor(45.5605, grad_fn=<MseLossBackward>),\n",
       " tensor(49.1200, grad_fn=<MseLossBackward>),\n",
       " tensor(54.8087, grad_fn=<MseLossBackward>),\n",
       " tensor(55.0155, grad_fn=<MseLossBackward>),\n",
       " tensor(61.5182, grad_fn=<MseLossBackward>),\n",
       " tensor(42.7897, grad_fn=<MseLossBackward>),\n",
       " tensor(41.0336, grad_fn=<MseLossBackward>),\n",
       " tensor(55.7303, grad_fn=<MseLossBackward>),\n",
       " tensor(53.0784, grad_fn=<MseLossBackward>),\n",
       " tensor(51.2999, grad_fn=<MseLossBackward>),\n",
       " tensor(33.4557, grad_fn=<MseLossBackward>),\n",
       " tensor(38.8022, grad_fn=<MseLossBackward>),\n",
       " tensor(52.7538, grad_fn=<MseLossBackward>),\n",
       " tensor(40.8453, grad_fn=<MseLossBackward>),\n",
       " tensor(41.7394, grad_fn=<MseLossBackward>),\n",
       " tensor(48.7652, grad_fn=<MseLossBackward>),\n",
       " tensor(35.5954, grad_fn=<MseLossBackward>),\n",
       " tensor(37.7506, grad_fn=<MseLossBackward>),\n",
       " tensor(61.5464, grad_fn=<MseLossBackward>),\n",
       " tensor(49.2143, grad_fn=<MseLossBackward>),\n",
       " tensor(41.9613, grad_fn=<MseLossBackward>),\n",
       " tensor(44.7674, grad_fn=<MseLossBackward>),\n",
       " tensor(43.1407, grad_fn=<MseLossBackward>),\n",
       " tensor(48.9956, grad_fn=<MseLossBackward>),\n",
       " tensor(36.6068, grad_fn=<MseLossBackward>),\n",
       " tensor(54.9920, grad_fn=<MseLossBackward>),\n",
       " tensor(49.0199, grad_fn=<MseLossBackward>),\n",
       " tensor(48.7823, grad_fn=<MseLossBackward>),\n",
       " tensor(50.8465, grad_fn=<MseLossBackward>),\n",
       " tensor(41.1941, grad_fn=<MseLossBackward>),\n",
       " tensor(39.3696, grad_fn=<MseLossBackward>),\n",
       " tensor(57.0612, grad_fn=<MseLossBackward>),\n",
       " tensor(53.0730, grad_fn=<MseLossBackward>),\n",
       " tensor(42.8274, grad_fn=<MseLossBackward>),\n",
       " tensor(45.1175, grad_fn=<MseLossBackward>),\n",
       " tensor(44.6919, grad_fn=<MseLossBackward>),\n",
       " tensor(48.5266, grad_fn=<MseLossBackward>),\n",
       " tensor(40.8647, grad_fn=<MseLossBackward>),\n",
       " tensor(32.2481, grad_fn=<MseLossBackward>),\n",
       " tensor(59.4428, grad_fn=<MseLossBackward>),\n",
       " tensor(49.8653, grad_fn=<MseLossBackward>),\n",
       " tensor(55.9813, grad_fn=<MseLossBackward>),\n",
       " tensor(58.8846, grad_fn=<MseLossBackward>),\n",
       " tensor(36.5396, grad_fn=<MseLossBackward>),\n",
       " tensor(44.8834, grad_fn=<MseLossBackward>),\n",
       " tensor(37.4792, grad_fn=<MseLossBackward>),\n",
       " tensor(49.1434, grad_fn=<MseLossBackward>),\n",
       " tensor(41.0932, grad_fn=<MseLossBackward>),\n",
       " tensor(44.3981, grad_fn=<MseLossBackward>),\n",
       " tensor(31.8406, grad_fn=<MseLossBackward>),\n",
       " tensor(59.0165, grad_fn=<MseLossBackward>),\n",
       " tensor(53.1460, grad_fn=<MseLossBackward>),\n",
       " tensor(45.9330, grad_fn=<MseLossBackward>),\n",
       " tensor(54.2248, grad_fn=<MseLossBackward>),\n",
       " tensor(44.5982, grad_fn=<MseLossBackward>),\n",
       " tensor(56.6021, grad_fn=<MseLossBackward>),\n",
       " tensor(32.1337, grad_fn=<MseLossBackward>),\n",
       " tensor(49.6223, grad_fn=<MseLossBackward>),\n",
       " tensor(58.8207, grad_fn=<MseLossBackward>),\n",
       " tensor(54.4775, grad_fn=<MseLossBackward>),\n",
       " tensor(49.9418, grad_fn=<MseLossBackward>),\n",
       " tensor(61.4706, grad_fn=<MseLossBackward>),\n",
       " tensor(53.4346, grad_fn=<MseLossBackward>),\n",
       " tensor(60.8445, grad_fn=<MseLossBackward>),\n",
       " tensor(47.1148, grad_fn=<MseLossBackward>),\n",
       " tensor(56.0720, grad_fn=<MseLossBackward>),\n",
       " tensor(69.3628, grad_fn=<MseLossBackward>),\n",
       " tensor(57.1059, grad_fn=<MseLossBackward>),\n",
       " tensor(48.4819, grad_fn=<MseLossBackward>),\n",
       " tensor(56.9065, grad_fn=<MseLossBackward>),\n",
       " tensor(33.9464, grad_fn=<MseLossBackward>),\n",
       " tensor(51.3192, grad_fn=<MseLossBackward>),\n",
       " tensor(53.0024, grad_fn=<MseLossBackward>),\n",
       " tensor(54.4748, grad_fn=<MseLossBackward>),\n",
       " tensor(54.9610, grad_fn=<MseLossBackward>),\n",
       " tensor(44.0510, grad_fn=<MseLossBackward>),\n",
       " tensor(49.4605, grad_fn=<MseLossBackward>),\n",
       " tensor(51.1194, grad_fn=<MseLossBackward>),\n",
       " tensor(40.7718, grad_fn=<MseLossBackward>),\n",
       " tensor(43.5028, grad_fn=<MseLossBackward>),\n",
       " tensor(38.9953, grad_fn=<MseLossBackward>),\n",
       " tensor(57.9210, grad_fn=<MseLossBackward>),\n",
       " tensor(50.1567, grad_fn=<MseLossBackward>),\n",
       " tensor(40.0438, grad_fn=<MseLossBackward>),\n",
       " tensor(45.3436, grad_fn=<MseLossBackward>),\n",
       " tensor(62.1758, grad_fn=<MseLossBackward>),\n",
       " tensor(45.7480, grad_fn=<MseLossBackward>),\n",
       " tensor(47.4495, grad_fn=<MseLossBackward>),\n",
       " tensor(46.5381, grad_fn=<MseLossBackward>),\n",
       " tensor(38.7144, grad_fn=<MseLossBackward>),\n",
       " tensor(49.1036, grad_fn=<MseLossBackward>),\n",
       " tensor(47.2807, grad_fn=<MseLossBackward>),\n",
       " tensor(53.3532, grad_fn=<MseLossBackward>),\n",
       " tensor(49.8898, grad_fn=<MseLossBackward>),\n",
       " tensor(49.1786, grad_fn=<MseLossBackward>),\n",
       " tensor(50.1470, grad_fn=<MseLossBackward>),\n",
       " tensor(54.2560, grad_fn=<MseLossBackward>),\n",
       " tensor(41.4222, grad_fn=<MseLossBackward>),\n",
       " tensor(46.7898, grad_fn=<MseLossBackward>),\n",
       " tensor(42.0393, grad_fn=<MseLossBackward>),\n",
       " tensor(56.9614, grad_fn=<MseLossBackward>),\n",
       " tensor(48.1490, grad_fn=<MseLossBackward>),\n",
       " tensor(53.7025, grad_fn=<MseLossBackward>),\n",
       " tensor(43.1398, grad_fn=<MseLossBackward>),\n",
       " tensor(54.0532, grad_fn=<MseLossBackward>),\n",
       " tensor(52.7528, grad_fn=<MseLossBackward>),\n",
       " tensor(55.7379, grad_fn=<MseLossBackward>),\n",
       " tensor(47.8140, grad_fn=<MseLossBackward>),\n",
       " tensor(43.7772, grad_fn=<MseLossBackward>),\n",
       " tensor(47.6676, grad_fn=<MseLossBackward>),\n",
       " tensor(39.4343, grad_fn=<MseLossBackward>),\n",
       " tensor(41.9994, grad_fn=<MseLossBackward>),\n",
       " tensor(38.2272, grad_fn=<MseLossBackward>),\n",
       " tensor(51.8060, grad_fn=<MseLossBackward>),\n",
       " tensor(51.5622, grad_fn=<MseLossBackward>),\n",
       " tensor(47.8923, grad_fn=<MseLossBackward>),\n",
       " tensor(39.5668, grad_fn=<MseLossBackward>),\n",
       " tensor(45.4761, grad_fn=<MseLossBackward>),\n",
       " tensor(47.2066, grad_fn=<MseLossBackward>),\n",
       " tensor(34.2982, grad_fn=<MseLossBackward>),\n",
       " tensor(46.5661, grad_fn=<MseLossBackward>),\n",
       " tensor(55.0600, grad_fn=<MseLossBackward>),\n",
       " tensor(34.5626, grad_fn=<MseLossBackward>),\n",
       " tensor(52.2084, grad_fn=<MseLossBackward>),\n",
       " tensor(34.7574, grad_fn=<MseLossBackward>),\n",
       " tensor(47.5846, grad_fn=<MseLossBackward>),\n",
       " tensor(45.0656, grad_fn=<MseLossBackward>),\n",
       " tensor(41.0400, grad_fn=<MseLossBackward>),\n",
       " tensor(39.9882, grad_fn=<MseLossBackward>),\n",
       " tensor(40.2820, grad_fn=<MseLossBackward>),\n",
       " tensor(43.2544, grad_fn=<MseLossBackward>),\n",
       " tensor(48.7408, grad_fn=<MseLossBackward>),\n",
       " tensor(26.3483, grad_fn=<MseLossBackward>),\n",
       " tensor(46.5844, grad_fn=<MseLossBackward>),\n",
       " tensor(45.0094, grad_fn=<MseLossBackward>),\n",
       " tensor(36.9812, grad_fn=<MseLossBackward>),\n",
       " tensor(39.9624, grad_fn=<MseLossBackward>),\n",
       " tensor(54.1874, grad_fn=<MseLossBackward>),\n",
       " tensor(58.8562, grad_fn=<MseLossBackward>),\n",
       " tensor(54.7445, grad_fn=<MseLossBackward>),\n",
       " tensor(53.9159, grad_fn=<MseLossBackward>),\n",
       " tensor(39.9765, grad_fn=<MseLossBackward>),\n",
       " tensor(41.9721, grad_fn=<MseLossBackward>),\n",
       " tensor(36.9121, grad_fn=<MseLossBackward>),\n",
       " tensor(46.0173, grad_fn=<MseLossBackward>),\n",
       " tensor(37.9256, grad_fn=<MseLossBackward>),\n",
       " tensor(42.4325, grad_fn=<MseLossBackward>),\n",
       " tensor(48.7923, grad_fn=<MseLossBackward>),\n",
       " tensor(43.1581, grad_fn=<MseLossBackward>),\n",
       " tensor(48.4863, grad_fn=<MseLossBackward>),\n",
       " tensor(48.9847, grad_fn=<MseLossBackward>),\n",
       " tensor(24.2219, grad_fn=<MseLossBackward>),\n",
       " tensor(38.4995, grad_fn=<MseLossBackward>),\n",
       " tensor(33.8286, grad_fn=<MseLossBackward>),\n",
       " tensor(53.3739, grad_fn=<MseLossBackward>),\n",
       " tensor(35.2768, grad_fn=<MseLossBackward>),\n",
       " tensor(46.7050, grad_fn=<MseLossBackward>),\n",
       " tensor(48.1780, grad_fn=<MseLossBackward>),\n",
       " tensor(47.0395, grad_fn=<MseLossBackward>),\n",
       " tensor(38.6900, grad_fn=<MseLossBackward>),\n",
       " tensor(40.8049, grad_fn=<MseLossBackward>),\n",
       " tensor(49.3211, grad_fn=<MseLossBackward>),\n",
       " tensor(46.0630, grad_fn=<MseLossBackward>),\n",
       " tensor(39.7525, grad_fn=<MseLossBackward>),\n",
       " tensor(51.2817, grad_fn=<MseLossBackward>),\n",
       " tensor(47.5457, grad_fn=<MseLossBackward>),\n",
       " tensor(40.1716, grad_fn=<MseLossBackward>),\n",
       " tensor(30.8330, grad_fn=<MseLossBackward>),\n",
       " tensor(29.3937, grad_fn=<MseLossBackward>),\n",
       " tensor(47.0742, grad_fn=<MseLossBackward>),\n",
       " tensor(40.7951, grad_fn=<MseLossBackward>),\n",
       " tensor(43.3881, grad_fn=<MseLossBackward>),\n",
       " tensor(34.0212, grad_fn=<MseLossBackward>),\n",
       " tensor(53.2415, grad_fn=<MseLossBackward>),\n",
       " tensor(49.2784, grad_fn=<MseLossBackward>),\n",
       " tensor(37.6651, grad_fn=<MseLossBackward>),\n",
       " tensor(33.4242, grad_fn=<MseLossBackward>),\n",
       " tensor(32.1346, grad_fn=<MseLossBackward>),\n",
       " tensor(30.1440, grad_fn=<MseLossBackward>),\n",
       " tensor(43.7196, grad_fn=<MseLossBackward>),\n",
       " tensor(47.4020, grad_fn=<MseLossBackward>),\n",
       " tensor(43.8134, grad_fn=<MseLossBackward>),\n",
       " tensor(39.0845, grad_fn=<MseLossBackward>),\n",
       " tensor(43.7358, grad_fn=<MseLossBackward>),\n",
       " tensor(35.5908, grad_fn=<MseLossBackward>),\n",
       " tensor(33.0125, grad_fn=<MseLossBackward>),\n",
       " tensor(43.4319, grad_fn=<MseLossBackward>),\n",
       " tensor(41.3811, grad_fn=<MseLossBackward>),\n",
       " tensor(42.3109, grad_fn=<MseLossBackward>),\n",
       " tensor(37.3582, grad_fn=<MseLossBackward>),\n",
       " tensor(42.6098, grad_fn=<MseLossBackward>),\n",
       " tensor(39.6490, grad_fn=<MseLossBackward>),\n",
       " tensor(47.0519, grad_fn=<MseLossBackward>),\n",
       " tensor(36.5904, grad_fn=<MseLossBackward>),\n",
       " tensor(35.7731, grad_fn=<MseLossBackward>),\n",
       " tensor(25.4467, grad_fn=<MseLossBackward>),\n",
       " tensor(36.9366, grad_fn=<MseLossBackward>),\n",
       " tensor(39.9638, grad_fn=<MseLossBackward>),\n",
       " tensor(44.6643, grad_fn=<MseLossBackward>),\n",
       " tensor(45.3394, grad_fn=<MseLossBackward>),\n",
       " tensor(42.2381, grad_fn=<MseLossBackward>),\n",
       " tensor(35.4448, grad_fn=<MseLossBackward>),\n",
       " tensor(30.4405, grad_fn=<MseLossBackward>),\n",
       " tensor(32.7107, grad_fn=<MseLossBackward>),\n",
       " tensor(38.3374, grad_fn=<MseLossBackward>),\n",
       " tensor(34.7823, grad_fn=<MseLossBackward>),\n",
       " tensor(49.3355, grad_fn=<MseLossBackward>),\n",
       " tensor(45.9828, grad_fn=<MseLossBackward>),\n",
       " tensor(35.9564, grad_fn=<MseLossBackward>),\n",
       " tensor(40.9388, grad_fn=<MseLossBackward>),\n",
       " tensor(45.0225, grad_fn=<MseLossBackward>),\n",
       " tensor(42.5294, grad_fn=<MseLossBackward>),\n",
       " tensor(47.4772, grad_fn=<MseLossBackward>),\n",
       " tensor(47.8131, grad_fn=<MseLossBackward>),\n",
       " tensor(35.6087, grad_fn=<MseLossBackward>),\n",
       " tensor(36.1629, grad_fn=<MseLossBackward>),\n",
       " tensor(43.9827, grad_fn=<MseLossBackward>),\n",
       " tensor(28.6287, grad_fn=<MseLossBackward>),\n",
       " tensor(30.2535, grad_fn=<MseLossBackward>),\n",
       " tensor(36.3031, grad_fn=<MseLossBackward>),\n",
       " tensor(38.7939, grad_fn=<MseLossBackward>),\n",
       " tensor(44.5741, grad_fn=<MseLossBackward>),\n",
       " tensor(49.3464, grad_fn=<MseLossBackward>),\n",
       " tensor(34.6113, grad_fn=<MseLossBackward>),\n",
       " tensor(30.1603, grad_fn=<MseLossBackward>),\n",
       " tensor(33.8914, grad_fn=<MseLossBackward>),\n",
       " tensor(39.8067, grad_fn=<MseLossBackward>),\n",
       " tensor(36.6399, grad_fn=<MseLossBackward>),\n",
       " tensor(39.4090, grad_fn=<MseLossBackward>),\n",
       " tensor(33.9494, grad_fn=<MseLossBackward>),\n",
       " tensor(37.0244, grad_fn=<MseLossBackward>),\n",
       " tensor(40.4896, grad_fn=<MseLossBackward>),\n",
       " tensor(33.4334, grad_fn=<MseLossBackward>),\n",
       " tensor(35.5396, grad_fn=<MseLossBackward>),\n",
       " tensor(28.6901, grad_fn=<MseLossBackward>),\n",
       " tensor(48.0862, grad_fn=<MseLossBackward>),\n",
       " tensor(36.0309, grad_fn=<MseLossBackward>),\n",
       " tensor(28.1596, grad_fn=<MseLossBackward>),\n",
       " tensor(39.0070, grad_fn=<MseLossBackward>),\n",
       " tensor(47.4920, grad_fn=<MseLossBackward>),\n",
       " tensor(44.8567, grad_fn=<MseLossBackward>),\n",
       " tensor(38.4638, grad_fn=<MseLossBackward>),\n",
       " tensor(39.3228, grad_fn=<MseLossBackward>),\n",
       " tensor(38.9937, grad_fn=<MseLossBackward>),\n",
       " tensor(48.1275, grad_fn=<MseLossBackward>),\n",
       " tensor(53.3927, grad_fn=<MseLossBackward>),\n",
       " tensor(44.0125, grad_fn=<MseLossBackward>),\n",
       " tensor(40.6076, grad_fn=<MseLossBackward>),\n",
       " tensor(49.3318, grad_fn=<MseLossBackward>),\n",
       " tensor(55.2225, grad_fn=<MseLossBackward>),\n",
       " tensor(45.0839, grad_fn=<MseLossBackward>),\n",
       " tensor(54.9848, grad_fn=<MseLossBackward>),\n",
       " tensor(28.3832, grad_fn=<MseLossBackward>),\n",
       " tensor(36.6488, grad_fn=<MseLossBackward>),\n",
       " tensor(32.8231, grad_fn=<MseLossBackward>),\n",
       " tensor(42.5833, grad_fn=<MseLossBackward>),\n",
       " tensor(35.2216, grad_fn=<MseLossBackward>),\n",
       " tensor(55.9664, grad_fn=<MseLossBackward>),\n",
       " tensor(45.8294, grad_fn=<MseLossBackward>),\n",
       " tensor(30.4592, grad_fn=<MseLossBackward>),\n",
       " tensor(35.4419, grad_fn=<MseLossBackward>),\n",
       " tensor(25.9435, grad_fn=<MseLossBackward>),\n",
       " tensor(38.2708, grad_fn=<MseLossBackward>),\n",
       " tensor(32.4249, grad_fn=<MseLossBackward>),\n",
       " tensor(44.1360, grad_fn=<MseLossBackward>),\n",
       " tensor(35.3712, grad_fn=<MseLossBackward>),\n",
       " tensor(32.8415, grad_fn=<MseLossBackward>),\n",
       " tensor(27.1811, grad_fn=<MseLossBackward>),\n",
       " tensor(35.6216, grad_fn=<MseLossBackward>),\n",
       " tensor(35.3120, grad_fn=<MseLossBackward>),\n",
       " tensor(29.6358, grad_fn=<MseLossBackward>),\n",
       " tensor(44.5427, grad_fn=<MseLossBackward>),\n",
       " tensor(39.6922, grad_fn=<MseLossBackward>),\n",
       " tensor(29.8869, grad_fn=<MseLossBackward>),\n",
       " tensor(37.2573, grad_fn=<MseLossBackward>),\n",
       " tensor(35.2111, grad_fn=<MseLossBackward>),\n",
       " tensor(37.5262, grad_fn=<MseLossBackward>),\n",
       " tensor(46.4610, grad_fn=<MseLossBackward>),\n",
       " tensor(31.9066, grad_fn=<MseLossBackward>),\n",
       " tensor(30.8006, grad_fn=<MseLossBackward>),\n",
       " tensor(40.4976, grad_fn=<MseLossBackward>),\n",
       " tensor(48.5895, grad_fn=<MseLossBackward>),\n",
       " tensor(41.4069, grad_fn=<MseLossBackward>),\n",
       " tensor(36.8940, grad_fn=<MseLossBackward>),\n",
       " tensor(47.6463, grad_fn=<MseLossBackward>),\n",
       " tensor(34.3434, grad_fn=<MseLossBackward>),\n",
       " tensor(48.1936, grad_fn=<MseLossBackward>),\n",
       " tensor(38.1112, grad_fn=<MseLossBackward>),\n",
       " tensor(35.6700, grad_fn=<MseLossBackward>),\n",
       " tensor(28.8370, grad_fn=<MseLossBackward>),\n",
       " tensor(35.3536, grad_fn=<MseLossBackward>),\n",
       " tensor(30.2512, grad_fn=<MseLossBackward>),\n",
       " tensor(33.3282, grad_fn=<MseLossBackward>),\n",
       " tensor(18.3070, grad_fn=<MseLossBackward>),\n",
       " tensor(29.9559, grad_fn=<MseLossBackward>),\n",
       " tensor(31.5228, grad_fn=<MseLossBackward>),\n",
       " tensor(31.5024, grad_fn=<MseLossBackward>),\n",
       " tensor(33.8400, grad_fn=<MseLossBackward>),\n",
       " tensor(41.4710, grad_fn=<MseLossBackward>),\n",
       " tensor(42.5710, grad_fn=<MseLossBackward>),\n",
       " tensor(42.8998, grad_fn=<MseLossBackward>),\n",
       " tensor(35.9841, grad_fn=<MseLossBackward>),\n",
       " tensor(32.6295, grad_fn=<MseLossBackward>),\n",
       " tensor(29.8869, grad_fn=<MseLossBackward>),\n",
       " tensor(36.1411, grad_fn=<MseLossBackward>),\n",
       " tensor(40.0851, grad_fn=<MseLossBackward>),\n",
       " tensor(42.5122, grad_fn=<MseLossBackward>),\n",
       " tensor(31.3297, grad_fn=<MseLossBackward>),\n",
       " tensor(38.7477, grad_fn=<MseLossBackward>),\n",
       " tensor(37.4983, grad_fn=<MseLossBackward>),\n",
       " tensor(30.3023, grad_fn=<MseLossBackward>),\n",
       " tensor(31.0740, grad_fn=<MseLossBackward>),\n",
       " tensor(42.6080, grad_fn=<MseLossBackward>),\n",
       " tensor(40.2628, grad_fn=<MseLossBackward>),\n",
       " tensor(36.7368, grad_fn=<MseLossBackward>),\n",
       " tensor(39.0666, grad_fn=<MseLossBackward>),\n",
       " tensor(34.1684, grad_fn=<MseLossBackward>),\n",
       " tensor(31.4629, grad_fn=<MseLossBackward>),\n",
       " tensor(39.1294, grad_fn=<MseLossBackward>),\n",
       " tensor(33.0134, grad_fn=<MseLossBackward>),\n",
       " tensor(16.0757, grad_fn=<MseLossBackward>),\n",
       " tensor(29.4170, grad_fn=<MseLossBackward>),\n",
       " tensor(45.0674, grad_fn=<MseLossBackward>),\n",
       " tensor(28.2920, grad_fn=<MseLossBackward>),\n",
       " tensor(30.5409, grad_fn=<MseLossBackward>),\n",
       " tensor(33.0957, grad_fn=<MseLossBackward>),\n",
       " tensor(31.9364, grad_fn=<MseLossBackward>),\n",
       " tensor(28.2458, grad_fn=<MseLossBackward>),\n",
       " tensor(32.1765, grad_fn=<MseLossBackward>),\n",
       " tensor(27.9220, grad_fn=<MseLossBackward>),\n",
       " tensor(38.0708, grad_fn=<MseLossBackward>),\n",
       " tensor(31.5449, grad_fn=<MseLossBackward>),\n",
       " tensor(37.0460, grad_fn=<MseLossBackward>),\n",
       " tensor(30.0936, grad_fn=<MseLossBackward>),\n",
       " tensor(43.8368, grad_fn=<MseLossBackward>),\n",
       " tensor(33.8753, grad_fn=<MseLossBackward>),\n",
       " tensor(25.0783, grad_fn=<MseLossBackward>),\n",
       " tensor(36.9941, grad_fn=<MseLossBackward>),\n",
       " tensor(26.5201, grad_fn=<MseLossBackward>),\n",
       " tensor(22.8865, grad_fn=<MseLossBackward>),\n",
       " tensor(35.0867, grad_fn=<MseLossBackward>),\n",
       " tensor(30.0837, grad_fn=<MseLossBackward>),\n",
       " tensor(24.6420, grad_fn=<MseLossBackward>),\n",
       " tensor(41.0766, grad_fn=<MseLossBackward>),\n",
       " tensor(29.2111, grad_fn=<MseLossBackward>),\n",
       " tensor(29.5617, grad_fn=<MseLossBackward>),\n",
       " tensor(28.8137, grad_fn=<MseLossBackward>),\n",
       " tensor(32.9008, grad_fn=<MseLossBackward>),\n",
       " tensor(31.9091, grad_fn=<MseLossBackward>),\n",
       " tensor(37.8307, grad_fn=<MseLossBackward>),\n",
       " tensor(30.5724, grad_fn=<MseLossBackward>),\n",
       " tensor(28.8088, grad_fn=<MseLossBackward>),\n",
       " tensor(26.3229, grad_fn=<MseLossBackward>),\n",
       " tensor(29.8278, grad_fn=<MseLossBackward>),\n",
       " tensor(36.8422, grad_fn=<MseLossBackward>),\n",
       " tensor(33.6151, grad_fn=<MseLossBackward>),\n",
       " tensor(31.4784, grad_fn=<MseLossBackward>),\n",
       " tensor(35.1011, grad_fn=<MseLossBackward>),\n",
       " tensor(27.5877, grad_fn=<MseLossBackward>),\n",
       " tensor(31.1730, grad_fn=<MseLossBackward>),\n",
       " tensor(20.1535, grad_fn=<MseLossBackward>),\n",
       " tensor(39.4378, grad_fn=<MseLossBackward>),\n",
       " tensor(37.0240, grad_fn=<MseLossBackward>),\n",
       " tensor(32.6399, grad_fn=<MseLossBackward>),\n",
       " tensor(27.4495, grad_fn=<MseLossBackward>),\n",
       " tensor(29.9110, grad_fn=<MseLossBackward>),\n",
       " tensor(21.6820, grad_fn=<MseLossBackward>),\n",
       " tensor(24.5976, grad_fn=<MseLossBackward>),\n",
       " tensor(25.7587, grad_fn=<MseLossBackward>),\n",
       " tensor(18.6697, grad_fn=<MseLossBackward>),\n",
       " tensor(36.9674, grad_fn=<MseLossBackward>),\n",
       " tensor(29.6202, grad_fn=<MseLossBackward>),\n",
       " tensor(26.5926, grad_fn=<MseLossBackward>),\n",
       " tensor(33.3736, grad_fn=<MseLossBackward>),\n",
       " tensor(32.8019, grad_fn=<MseLossBackward>),\n",
       " tensor(29.1055, grad_fn=<MseLossBackward>),\n",
       " tensor(24.7065, grad_fn=<MseLossBackward>),\n",
       " tensor(32.1288, grad_fn=<MseLossBackward>),\n",
       " tensor(36.6740, grad_fn=<MseLossBackward>),\n",
       " tensor(23.7873, grad_fn=<MseLossBackward>),\n",
       " tensor(31.2872, grad_fn=<MseLossBackward>),\n",
       " tensor(34.9243, grad_fn=<MseLossBackward>),\n",
       " tensor(33.3837, grad_fn=<MseLossBackward>),\n",
       " tensor(27.2269, grad_fn=<MseLossBackward>),\n",
       " tensor(27.0929, grad_fn=<MseLossBackward>),\n",
       " tensor(21.9829, grad_fn=<MseLossBackward>),\n",
       " tensor(31.2638, grad_fn=<MseLossBackward>),\n",
       " tensor(17.2900, grad_fn=<MseLossBackward>),\n",
       " tensor(29.1611, grad_fn=<MseLossBackward>),\n",
       " tensor(29.6158, grad_fn=<MseLossBackward>),\n",
       " tensor(33.8373, grad_fn=<MseLossBackward>),\n",
       " tensor(30.2134, grad_fn=<MseLossBackward>),\n",
       " tensor(29.6892, grad_fn=<MseLossBackward>),\n",
       " tensor(20.9221, grad_fn=<MseLossBackward>),\n",
       " tensor(19.5738, grad_fn=<MseLossBackward>),\n",
       " tensor(23.3844, grad_fn=<MseLossBackward>),\n",
       " tensor(38.9338, grad_fn=<MseLossBackward>),\n",
       " tensor(27.0124, grad_fn=<MseLossBackward>),\n",
       " tensor(21.9706, grad_fn=<MseLossBackward>),\n",
       " tensor(26.2405, grad_fn=<MseLossBackward>),\n",
       " tensor(32.7907, grad_fn=<MseLossBackward>),\n",
       " tensor(22.6510, grad_fn=<MseLossBackward>),\n",
       " tensor(27.0771, grad_fn=<MseLossBackward>),\n",
       " tensor(32.8892, grad_fn=<MseLossBackward>),\n",
       " tensor(24.7489, grad_fn=<MseLossBackward>),\n",
       " tensor(26.5355, grad_fn=<MseLossBackward>),\n",
       " tensor(32.5098, grad_fn=<MseLossBackward>),\n",
       " tensor(34.1742, grad_fn=<MseLossBackward>),\n",
       " tensor(27.7800, grad_fn=<MseLossBackward>),\n",
       " tensor(23.0786, grad_fn=<MseLossBackward>),\n",
       " tensor(36.4091, grad_fn=<MseLossBackward>),\n",
       " tensor(28.1104, grad_fn=<MseLossBackward>),\n",
       " tensor(28.7698, grad_fn=<MseLossBackward>),\n",
       " tensor(14.2720, grad_fn=<MseLossBackward>),\n",
       " tensor(33.9887, grad_fn=<MseLossBackward>),\n",
       " tensor(22.1560, grad_fn=<MseLossBackward>),\n",
       " tensor(24.6855, grad_fn=<MseLossBackward>),\n",
       " tensor(26.7767, grad_fn=<MseLossBackward>),\n",
       " tensor(21.3248, grad_fn=<MseLossBackward>),\n",
       " tensor(32.7216, grad_fn=<MseLossBackward>),\n",
       " tensor(25.8213, grad_fn=<MseLossBackward>),\n",
       " tensor(24.4899, grad_fn=<MseLossBackward>),\n",
       " tensor(25.6469, grad_fn=<MseLossBackward>),\n",
       " tensor(19.3006, grad_fn=<MseLossBackward>),\n",
       " tensor(21.8481, grad_fn=<MseLossBackward>),\n",
       " tensor(37.2495, grad_fn=<MseLossBackward>),\n",
       " tensor(32.4967, grad_fn=<MseLossBackward>),\n",
       " tensor(28.4177, grad_fn=<MseLossBackward>),\n",
       " tensor(28.3053, grad_fn=<MseLossBackward>),\n",
       " tensor(31.1307, grad_fn=<MseLossBackward>),\n",
       " tensor(21.6277, grad_fn=<MseLossBackward>),\n",
       " tensor(20.3356, grad_fn=<MseLossBackward>),\n",
       " tensor(25.4643, grad_fn=<MseLossBackward>),\n",
       " tensor(28.4251, grad_fn=<MseLossBackward>),\n",
       " tensor(23.1923, grad_fn=<MseLossBackward>),\n",
       " tensor(26.4550, grad_fn=<MseLossBackward>),\n",
       " tensor(30.0807, grad_fn=<MseLossBackward>),\n",
       " tensor(19.1093, grad_fn=<MseLossBackward>),\n",
       " tensor(19.5092, grad_fn=<MseLossBackward>),\n",
       " tensor(19.7381, grad_fn=<MseLossBackward>),\n",
       " tensor(28.6996, grad_fn=<MseLossBackward>),\n",
       " tensor(24.2729, grad_fn=<MseLossBackward>),\n",
       " tensor(31.0888, grad_fn=<MseLossBackward>),\n",
       " tensor(26.3469, grad_fn=<MseLossBackward>),\n",
       " tensor(25.4539, grad_fn=<MseLossBackward>),\n",
       " tensor(22.5040, grad_fn=<MseLossBackward>),\n",
       " tensor(28.3048, grad_fn=<MseLossBackward>),\n",
       " tensor(27.6230, grad_fn=<MseLossBackward>),\n",
       " tensor(28.7402, grad_fn=<MseLossBackward>),\n",
       " tensor(30.0163, grad_fn=<MseLossBackward>),\n",
       " tensor(28.3495, grad_fn=<MseLossBackward>),\n",
       " tensor(23.0832, grad_fn=<MseLossBackward>),\n",
       " tensor(32.5388, grad_fn=<MseLossBackward>),\n",
       " tensor(27.7274, grad_fn=<MseLossBackward>),\n",
       " tensor(17.7311, grad_fn=<MseLossBackward>),\n",
       " tensor(14.9114, grad_fn=<MseLossBackward>),\n",
       " tensor(24.8211, grad_fn=<MseLossBackward>),\n",
       " tensor(28.9953, grad_fn=<MseLossBackward>),\n",
       " tensor(32.7892, grad_fn=<MseLossBackward>),\n",
       " tensor(30.7684, grad_fn=<MseLossBackward>),\n",
       " tensor(27.8137, grad_fn=<MseLossBackward>),\n",
       " tensor(21.9944, grad_fn=<MseLossBackward>),\n",
       " tensor(25.8831, grad_fn=<MseLossBackward>),\n",
       " tensor(19.7750, grad_fn=<MseLossBackward>),\n",
       " tensor(31.2777, grad_fn=<MseLossBackward>),\n",
       " tensor(29.4951, grad_fn=<MseLossBackward>),\n",
       " tensor(27.9355, grad_fn=<MseLossBackward>),\n",
       " tensor(26.6640, grad_fn=<MseLossBackward>),\n",
       " tensor(21.9982, grad_fn=<MseLossBackward>),\n",
       " tensor(33.7571, grad_fn=<MseLossBackward>),\n",
       " tensor(23.9764, grad_fn=<MseLossBackward>),\n",
       " tensor(23.4620, grad_fn=<MseLossBackward>),\n",
       " tensor(28.4034, grad_fn=<MseLossBackward>),\n",
       " tensor(19.4414, grad_fn=<MseLossBackward>),\n",
       " tensor(23.4283, grad_fn=<MseLossBackward>),\n",
       " tensor(28.1721, grad_fn=<MseLossBackward>),\n",
       " tensor(26.0240, grad_fn=<MseLossBackward>),\n",
       " tensor(28.4947, grad_fn=<MseLossBackward>),\n",
       " tensor(18.5542, grad_fn=<MseLossBackward>),\n",
       " tensor(30.6248, grad_fn=<MseLossBackward>),\n",
       " tensor(21.2099, grad_fn=<MseLossBackward>),\n",
       " tensor(34.7103, grad_fn=<MseLossBackward>),\n",
       " tensor(16.3371, grad_fn=<MseLossBackward>),\n",
       " tensor(26.2501, grad_fn=<MseLossBackward>),\n",
       " tensor(19.0193, grad_fn=<MseLossBackward>),\n",
       " tensor(28.4024, grad_fn=<MseLossBackward>),\n",
       " tensor(20.6609, grad_fn=<MseLossBackward>),\n",
       " tensor(24.8365, grad_fn=<MseLossBackward>),\n",
       " tensor(27.3359, grad_fn=<MseLossBackward>),\n",
       " tensor(18.3567, grad_fn=<MseLossBackward>),\n",
       " tensor(24.0406, grad_fn=<MseLossBackward>),\n",
       " tensor(33.3198, grad_fn=<MseLossBackward>),\n",
       " tensor(30.2905, grad_fn=<MseLossBackward>),\n",
       " tensor(23.8458, grad_fn=<MseLossBackward>),\n",
       " tensor(21.9956, grad_fn=<MseLossBackward>),\n",
       " tensor(27.2400, grad_fn=<MseLossBackward>),\n",
       " tensor(18.7942, grad_fn=<MseLossBackward>),\n",
       " tensor(27.2189, grad_fn=<MseLossBackward>),\n",
       " tensor(20.8156, grad_fn=<MseLossBackward>),\n",
       " tensor(32.6652, grad_fn=<MseLossBackward>),\n",
       " tensor(29.4284, grad_fn=<MseLossBackward>),\n",
       " tensor(25.0016, grad_fn=<MseLossBackward>),\n",
       " tensor(25.5549, grad_fn=<MseLossBackward>),\n",
       " tensor(18.0487, grad_fn=<MseLossBackward>),\n",
       " tensor(19.3794, grad_fn=<MseLossBackward>),\n",
       " tensor(17.7124, grad_fn=<MseLossBackward>),\n",
       " tensor(26.2264, grad_fn=<MseLossBackward>),\n",
       " tensor(24.1769, grad_fn=<MseLossBackward>),\n",
       " tensor(25.0141, grad_fn=<MseLossBackward>),\n",
       " tensor(30.0575, grad_fn=<MseLossBackward>),\n",
       " tensor(22.1294, grad_fn=<MseLossBackward>),\n",
       " tensor(15.2733, grad_fn=<MseLossBackward>),\n",
       " tensor(29.3584, grad_fn=<MseLossBackward>),\n",
       " tensor(23.6517, grad_fn=<MseLossBackward>),\n",
       " tensor(33.1055, grad_fn=<MseLossBackward>),\n",
       " tensor(17.8692, grad_fn=<MseLossBackward>),\n",
       " tensor(35.4523, grad_fn=<MseLossBackward>),\n",
       " tensor(17.6885, grad_fn=<MseLossBackward>),\n",
       " tensor(22.2363, grad_fn=<MseLossBackward>),\n",
       " tensor(21.5441, grad_fn=<MseLossBackward>),\n",
       " tensor(20.1283, grad_fn=<MseLossBackward>),\n",
       " tensor(23.6521, grad_fn=<MseLossBackward>),\n",
       " tensor(20.2639, grad_fn=<MseLossBackward>),\n",
       " tensor(19.5695, grad_fn=<MseLossBackward>),\n",
       " tensor(26.3544, grad_fn=<MseLossBackward>),\n",
       " tensor(30.2346, grad_fn=<MseLossBackward>),\n",
       " tensor(28.8574, grad_fn=<MseLossBackward>),\n",
       " tensor(20.4357, grad_fn=<MseLossBackward>),\n",
       " tensor(35.6747, grad_fn=<MseLossBackward>),\n",
       " tensor(21.4013, grad_fn=<MseLossBackward>),\n",
       " tensor(17.7132, grad_fn=<MseLossBackward>),\n",
       " tensor(27.2845, grad_fn=<MseLossBackward>),\n",
       " tensor(28.0122, grad_fn=<MseLossBackward>),\n",
       " tensor(22.2724, grad_fn=<MseLossBackward>),\n",
       " tensor(23.9229, grad_fn=<MseLossBackward>),\n",
       " tensor(27.4955, grad_fn=<MseLossBackward>),\n",
       " tensor(22.5897, grad_fn=<MseLossBackward>),\n",
       " tensor(26.8400, grad_fn=<MseLossBackward>),\n",
       " tensor(25.4910, grad_fn=<MseLossBackward>),\n",
       " tensor(22.2424, grad_fn=<MseLossBackward>),\n",
       " tensor(27.4832, grad_fn=<MseLossBackward>),\n",
       " tensor(17.9971, grad_fn=<MseLossBackward>),\n",
       " tensor(27.5924, grad_fn=<MseLossBackward>),\n",
       " tensor(32.7758, grad_fn=<MseLossBackward>),\n",
       " tensor(16.5415, grad_fn=<MseLossBackward>),\n",
       " tensor(24.5708, grad_fn=<MseLossBackward>),\n",
       " tensor(31.1650, grad_fn=<MseLossBackward>),\n",
       " tensor(16.7236, grad_fn=<MseLossBackward>),\n",
       " tensor(19.0703, grad_fn=<MseLossBackward>),\n",
       " tensor(17.5449, grad_fn=<MseLossBackward>),\n",
       " tensor(26.9471, grad_fn=<MseLossBackward>),\n",
       " tensor(21.0737, grad_fn=<MseLossBackward>),\n",
       " tensor(18.9947, grad_fn=<MseLossBackward>),\n",
       " tensor(25.6213, grad_fn=<MseLossBackward>),\n",
       " tensor(24.1673, grad_fn=<MseLossBackward>),\n",
       " tensor(20.9887, grad_fn=<MseLossBackward>),\n",
       " tensor(23.2120, grad_fn=<MseLossBackward>),\n",
       " tensor(27.9963, grad_fn=<MseLossBackward>),\n",
       " tensor(22.7510, grad_fn=<MseLossBackward>),\n",
       " tensor(21.4344, grad_fn=<MseLossBackward>),\n",
       " tensor(23.2823, grad_fn=<MseLossBackward>),\n",
       " tensor(15.5426, grad_fn=<MseLossBackward>),\n",
       " tensor(24.4554, grad_fn=<MseLossBackward>),\n",
       " tensor(20.9190, grad_fn=<MseLossBackward>),\n",
       " tensor(20.4218, grad_fn=<MseLossBackward>),\n",
       " tensor(23.1373, grad_fn=<MseLossBackward>),\n",
       " tensor(19.8771, grad_fn=<MseLossBackward>),\n",
       " tensor(18.1583, grad_fn=<MseLossBackward>),\n",
       " tensor(22.7157, grad_fn=<MseLossBackward>),\n",
       " tensor(26.1509, grad_fn=<MseLossBackward>),\n",
       " tensor(20.1494, grad_fn=<MseLossBackward>),\n",
       " tensor(20.1927, grad_fn=<MseLossBackward>),\n",
       " tensor(33.4300, grad_fn=<MseLossBackward>),\n",
       " tensor(19.6888, grad_fn=<MseLossBackward>),\n",
       " tensor(23.4472, grad_fn=<MseLossBackward>),\n",
       " tensor(23.6690, grad_fn=<MseLossBackward>),\n",
       " tensor(24.3062, grad_fn=<MseLossBackward>),\n",
       " tensor(32.4238, grad_fn=<MseLossBackward>),\n",
       " tensor(13.9592, grad_fn=<MseLossBackward>),\n",
       " tensor(25.1540, grad_fn=<MseLossBackward>),\n",
       " tensor(18.5412, grad_fn=<MseLossBackward>),\n",
       " tensor(21.0415, grad_fn=<MseLossBackward>),\n",
       " tensor(23.3313, grad_fn=<MseLossBackward>),\n",
       " tensor(27.7550, grad_fn=<MseLossBackward>),\n",
       " tensor(28.3965, grad_fn=<MseLossBackward>),\n",
       " tensor(23.0058, grad_fn=<MseLossBackward>),\n",
       " tensor(20.7518, grad_fn=<MseLossBackward>),\n",
       " tensor(30.3634, grad_fn=<MseLossBackward>),\n",
       " tensor(26.4489, grad_fn=<MseLossBackward>),\n",
       " tensor(20.1840, grad_fn=<MseLossBackward>),\n",
       " tensor(20.5967, grad_fn=<MseLossBackward>),\n",
       " tensor(24.0493, grad_fn=<MseLossBackward>),\n",
       " tensor(16.7212, grad_fn=<MseLossBackward>),\n",
       " tensor(21.0596, grad_fn=<MseLossBackward>),\n",
       " tensor(24.8308, grad_fn=<MseLossBackward>),\n",
       " tensor(20.4898, grad_fn=<MseLossBackward>),\n",
       " tensor(25.0599, grad_fn=<MseLossBackward>),\n",
       " tensor(26.7252, grad_fn=<MseLossBackward>),\n",
       " tensor(34.4991, grad_fn=<MseLossBackward>),\n",
       " tensor(20.4382, grad_fn=<MseLossBackward>),\n",
       " tensor(14.6824, grad_fn=<MseLossBackward>),\n",
       " tensor(19.9704, grad_fn=<MseLossBackward>),\n",
       " tensor(19.9396, grad_fn=<MseLossBackward>),\n",
       " tensor(23.2533, grad_fn=<MseLossBackward>),\n",
       " tensor(32.3485, grad_fn=<MseLossBackward>),\n",
       " tensor(24.6664, grad_fn=<MseLossBackward>),\n",
       " tensor(17.1873, grad_fn=<MseLossBackward>),\n",
       " tensor(29.0165, grad_fn=<MseLossBackward>),\n",
       " tensor(14.9400, grad_fn=<MseLossBackward>),\n",
       " tensor(30.6928, grad_fn=<MseLossBackward>),\n",
       " tensor(32.6212, grad_fn=<MseLossBackward>),\n",
       " tensor(20.3802, grad_fn=<MseLossBackward>),\n",
       " tensor(23.1634, grad_fn=<MseLossBackward>),\n",
       " tensor(20.1381, grad_fn=<MseLossBackward>),\n",
       " tensor(22.4346, grad_fn=<MseLossBackward>),\n",
       " tensor(22.5529, grad_fn=<MseLossBackward>),\n",
       " tensor(10.5714, grad_fn=<MseLossBackward>),\n",
       " tensor(26.8065, grad_fn=<MseLossBackward>),\n",
       " tensor(15.6519, grad_fn=<MseLossBackward>),\n",
       " tensor(16.6267, grad_fn=<MseLossBackward>),\n",
       " tensor(17.2438, grad_fn=<MseLossBackward>),\n",
       " tensor(21.9760, grad_fn=<MseLossBackward>),\n",
       " tensor(16.6633, grad_fn=<MseLossBackward>),\n",
       " tensor(27.9227, grad_fn=<MseLossBackward>),\n",
       " tensor(13.5603, grad_fn=<MseLossBackward>),\n",
       " tensor(23.1558, grad_fn=<MseLossBackward>),\n",
       " tensor(24.5454, grad_fn=<MseLossBackward>),\n",
       " tensor(25.5443, grad_fn=<MseLossBackward>),\n",
       " tensor(29.5505, grad_fn=<MseLossBackward>),\n",
       " tensor(20.6870, grad_fn=<MseLossBackward>),\n",
       " tensor(23.7318, grad_fn=<MseLossBackward>),\n",
       " tensor(18.8265, grad_fn=<MseLossBackward>),\n",
       " tensor(22.2952, grad_fn=<MseLossBackward>),\n",
       " tensor(25.7578, grad_fn=<MseLossBackward>),\n",
       " tensor(25.5525, grad_fn=<MseLossBackward>),\n",
       " tensor(21.4577, grad_fn=<MseLossBackward>),\n",
       " tensor(23.4420, grad_fn=<MseLossBackward>),\n",
       " tensor(15.9988, grad_fn=<MseLossBackward>),\n",
       " tensor(24.5880, grad_fn=<MseLossBackward>),\n",
       " tensor(22.0107, grad_fn=<MseLossBackward>),\n",
       " tensor(20.1624, grad_fn=<MseLossBackward>),\n",
       " tensor(18.5254, grad_fn=<MseLossBackward>),\n",
       " tensor(14.8402, grad_fn=<MseLossBackward>),\n",
       " tensor(18.4010, grad_fn=<MseLossBackward>),\n",
       " tensor(19.2232, grad_fn=<MseLossBackward>),\n",
       " tensor(20.0553, grad_fn=<MseLossBackward>),\n",
       " tensor(17.6383, grad_fn=<MseLossBackward>),\n",
       " tensor(13.8337, grad_fn=<MseLossBackward>),\n",
       " tensor(23.9226, grad_fn=<MseLossBackward>),\n",
       " tensor(16.8317, grad_fn=<MseLossBackward>),\n",
       " tensor(17.0439, grad_fn=<MseLossBackward>),\n",
       " tensor(20.2948, grad_fn=<MseLossBackward>),\n",
       " tensor(26.0865, grad_fn=<MseLossBackward>),\n",
       " tensor(25.8033, grad_fn=<MseLossBackward>),\n",
       " tensor(24.9612, grad_fn=<MseLossBackward>),\n",
       " tensor(24.0460, grad_fn=<MseLossBackward>),\n",
       " tensor(21.7330, grad_fn=<MseLossBackward>),\n",
       " tensor(19.9407, grad_fn=<MseLossBackward>),\n",
       " tensor(20.5855, grad_fn=<MseLossBackward>),\n",
       " tensor(20.6522, grad_fn=<MseLossBackward>),\n",
       " tensor(19.6931, grad_fn=<MseLossBackward>),\n",
       " tensor(11.9993, grad_fn=<MseLossBackward>),\n",
       " tensor(14.8880, grad_fn=<MseLossBackward>),\n",
       " tensor(21.2132, grad_fn=<MseLossBackward>),\n",
       " tensor(14.4727, grad_fn=<MseLossBackward>),\n",
       " tensor(19.9862, grad_fn=<MseLossBackward>),\n",
       " tensor(21.6334, grad_fn=<MseLossBackward>),\n",
       " tensor(23.9830, grad_fn=<MseLossBackward>),\n",
       " tensor(12.5700, grad_fn=<MseLossBackward>),\n",
       " tensor(18.1785, grad_fn=<MseLossBackward>),\n",
       " tensor(24.3514, grad_fn=<MseLossBackward>),\n",
       " tensor(15.3752, grad_fn=<MseLossBackward>),\n",
       " tensor(16.3530, grad_fn=<MseLossBackward>),\n",
       " tensor(25.7385, grad_fn=<MseLossBackward>),\n",
       " tensor(24.7860, grad_fn=<MseLossBackward>),\n",
       " tensor(26.1170, grad_fn=<MseLossBackward>),\n",
       " tensor(14.5514, grad_fn=<MseLossBackward>),\n",
       " tensor(22.5103, grad_fn=<MseLossBackward>),\n",
       " tensor(8.6744, grad_fn=<MseLossBackward>),\n",
       " tensor(24.9991, grad_fn=<MseLossBackward>),\n",
       " tensor(23.3389, grad_fn=<MseLossBackward>),\n",
       " tensor(13.0112, grad_fn=<MseLossBackward>),\n",
       " tensor(15.9522, grad_fn=<MseLossBackward>),\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
